{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d35a47-136e-4b7d-a417-28466d595386",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To do:\n",
    "next: add image features from CNN into autoencoder and isolation forest\n",
    "1) figure out how to feature engineer with images (rotations, crops, etc.)\n",
    "2) load images and metadata into autoencoder and get predictions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79a54bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import tensorflow as tf\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed058f-8682-4c61-815c-1bcb643be5a4",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cfd6d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions to load, process, and feature extract the images\n",
    "def extract_features(img_batch):\n",
    "    \"\"\"\n",
    "    Extracts features from a batch of images using ResNet50\n",
    "    \n",
    "    :param img_batch: batch of images as numpy arrays\n",
    "    :return: feature vectors for the batch\n",
    "    \"\"\"\n",
    "    # Preprocess batch images to align with ResNet50 requirements\n",
    "    img_batch = np.array([preprocess_input(img) for img in img_batch])\n",
    "    \n",
    "    # Extract features for the entire batch\n",
    "    features = resnet_model.predict(img_batch, verbose=0)\n",
    "    \n",
    "    # Flatten and return the features\n",
    "    return features.reshape(features.shape[0], -1)\n",
    "\n",
    "def load_image(zip_fold, file, img_size):\n",
    "    \"\"\"\n",
    "    Loads and resizes an image from a zip folder\n",
    "    \n",
    "    :param zip_fold: zipped folder object\n",
    "    :param file: filename for image in zip folder\n",
    "    :param img_size: target size for resizing\n",
    "    :return: image as a numpy array\n",
    "    \"\"\"\n",
    "    with zip_fold.open(file) as img_file:\n",
    "        img = load_img(BytesIO(img_file.read()), target_size=img_size)\n",
    "        return img_to_array(img)\n",
    "\n",
    "def get_batch_features(files, z, img_size=(224, 224), batch_size=32, num_workers=4):\n",
    "    \"\"\"\n",
    "    Loads images and extracts feautres with batch processing and a ResNet50 model\n",
    "    \n",
    "    :param files: list of filenames for images\n",
    "    :param z: zipped folder object\n",
    "    :param img_size: target size to resize images\n",
    "    :param batch_size: number of images per batch\n",
    "    :param num_workers: number of threads for parallel processing\n",
    "    :return: feature vectors for images in batches\n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    # Process images in batches\n",
    "    for i in range(0, len(files), batch_size):\n",
    "        batch_files = files[i:i + batch_size]\n",
    "\n",
    "        # Load and preprocess images in parallel\n",
    "        with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "            img_batch = list(executor.map(lambda file: load_image(z, file, img_size), batch_files))\n",
    "\n",
    "        # Extract features for the batch\n",
    "        img_batch = np.array(img_batch)\n",
    "        features = extract_features(img_batch)\n",
    "            \n",
    "        yield features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a1ce8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the metadata\n",
    "zip_folder = zipfile.ZipFile('anon-patient-data.zip')\n",
    "skin_cancer_df = pd.read_csv(zip_folder.open('train-metadata.csv'), low_memory=False, \n",
    "                            usecols=[num for num in range(0, 43) if num not in [2, 7]], index_col='isic_id')\n",
    "\n",
    "# Randomly undersample the non-cancerous individuals from the dataset\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=0.31)\n",
    "skin_cancer_df, targets = rus.fit(skin_cancer_df.drop('target'), skin_cancer_df['target'])\n",
    "img_files = [file[6:-4] for file in zip_folder.namelist() if file.startswith('image/')]\n",
    "removed_samples = rus.sample_indices_\n",
    "removed_samples\n",
    "\"\"\"\n",
    "# Load the pre-trained ResNet50 model\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Obtain all JPG image filenames and initialize array for image features\n",
    "img_files = [file for file in zip_folder.namelist() if file.startswith('image/') and file.endswith('.jpg')]\n",
    "images_features = np.zeros((len(img_files), 2048))\n",
    "\n",
    "# Extract image features using ResNet50 and batch processsing\n",
    "idx = 0\n",
    "for batch_features in get_batch_features(img_files, zip_folder, img_size=(224, 224), batch_size=64, num_workers=4):\n",
    "    batch_length = batch_features.shape[0]\n",
    "    images_features[idx:idx + batch_length] = batch_features\n",
    "    idx += batch_length\n",
    "    \n",
    "# Save image data into CSV to avoid unnecesary repetition of ResNet50 process\n",
    "pd.DataFrame(images_features).to_csv('resnet50_features.csv', index=False, header=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35061f7b-6f3f-4903-ac86-78516eef4098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV data containing image features from ResNet50 processing commented out above\n",
    "images_features = np.loadtxt('resnet50_features.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded8fa8-355f-438d-9396-1768d954cbc8",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of Metadata by Lesion Type (Cancer vs Non-Cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaf24b9-b4c6-4057-892d-28a4d03030e4",
   "metadata": {},
   "source": [
    "### How balanced is the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd2928-db81-494a-8868-ab14f0cc2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the number of cancerous vs non-cancerous lesions in the data\n",
    "not_cancer = skin_cancer_df[skin_cancer_df['target'] == 0]\n",
    "cancer = skin_cancer_df[skin_cancer_df['target'] == 1]\n",
    "print(f'Out of the {len(skin_cancer_df)} lesions in our dataset, {len(not_cancer)} are not cancerous and {len(cancer)} are cancerous.')\n",
    "\n",
    "# Visualize the results in a pie chart\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie([len(not_cancer), len(cancer)], labels=['Not Cancer', 'Cancer'], autopct='%1.1f%%')\n",
    "ax.set_title('Proportion of Cancerous vs Non-Cancerous Lesions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98afe0bc-a75e-488f-992f-1fb90cd1cb6f",
   "metadata": {},
   "source": [
    "#### The data is heavily imbalanced, with almost all available lesions being non-cancerous. This characteristic of the data is our primary motivator for utilizing anomaly detection rather than binary classification as our method for cancer detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6135be-ced6-4818-8c92-ff25335dd8e6",
   "metadata": {},
   "source": [
    "### Do men and women make up different proportions of cancerous vs non-cancerous lesions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759724c1-203b-443c-b12f-f24dc9e97e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the frequencies of each sex for cancerous and non-cancerous lesions\n",
    "gender_freqs_cancer = Counter(cancer['sex'])\n",
    "gender_freqs_noncancer = Counter(not_cancer['sex'])\n",
    "\n",
    "# Visualize the frequencies\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].pie([gender_freqs_noncancer['male'], gender_freqs_noncancer['female'], gender_freqs_noncancer[np.nan]],\n",
    "       labels=['male', 'female', 'NA'], autopct='%1.1f%%')\n",
    "ax[0].set_title('Non-Cancerous Patients')\n",
    "ax[1].pie([gender_freqs_cancer['male'], gender_freqs_cancer['female'], gender_freqs_cancer[np.nan]],\n",
    "       labels=['male', 'female', 'NA'], autopct='%1.1f%%')\n",
    "ax[1].set_title('Cancerous Patients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36365eb6-8c83-42a8-867f-688ea24bce43",
   "metadata": {},
   "source": [
    "#### Men are more represented in cancerous lesions than non-cancerous lesions, which aligns with the notion that men are more likely to obtain skin cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9d5c89-7c82-4499-b262-c3f050b808a0",
   "metadata": {},
   "source": [
    "### Is there a significant difference in the age distribution for cancerous vs non-cancerous patients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578bb0cc-efaa-447e-9e8b-fd6da0a3a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the age distributions\n",
    "plt.hist(cancer['age_approx'], histtype='step', color='red', density=True, label='Cancerous')\n",
    "plt.hist(not_cancer['age_approx'], histtype='step', color='green', density=True, label='Non-Cancerous')\n",
    "plt.legend()\n",
    "plt.xlabel('Age Approximations')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Age Distribution of Cancerous vs Non-Cancerous Patients')\n",
    "plt.show()\n",
    "\n",
    "# Perform the Mann-Whitney U test\n",
    "u_stat, p_value = stats.mannwhitneyu(cancer['age_approx'], not_cancer['age_approx'])\n",
    "\n",
    "# Print the result\n",
    "print(f'Mann-Whitney U test: U-stat = {u_stat}, p-value = {p_value}')\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print('There is a significant difference in the age distribution between cancerous and non-cancerous patients.')\n",
    "else:\n",
    "    print('There is no significant difference in the age distribution between cancerous and non-cancerous patients.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312f25af-0b8b-46ad-8ef3-308ca6249774",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c1bd2-729e-4ff3-bbf7-1792952575a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to compare summary stats for (choose columns that align with the ABCD factors used for skin cancer detection)\n",
    "use_cols = ['tbp_lv_symm_2axis', 'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean', 'clin_size_long_diam_mm']\n",
    "\n",
    "# Present summary statistics for cancerous patients\n",
    "cancer[use_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dfd094-e95c-4bd2-bec5-fb26588fd57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Present summary statistics for non-cancerous patients\n",
    "not_cancer[use_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d6cb8-bd14-4daa-ad13-380d15ec245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Mann-Whitney U test to determine if any of these differences are significant\n",
    "for col in use_cols:\n",
    "    u_stat, p_value = stats.mannwhitneyu(cancer[col], not_cancer[col])\n",
    "    if p_value < 0.05:\n",
    "        print(f'There is a significant difference in {col} between cancerous and non-cancerous patients.')\n",
    "    else:\n",
    "        print(f'There is no significant difference in {col} between cancerous and non-cancerous patients.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65023dfd-22e5-481f-bbb1-31bbd0f6c0e2",
   "metadata": {},
   "source": [
    "### Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bdff5d-9df6-4fae-b02d-ac13d4c99725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with null values for non-cancerous patients\n",
    "not_cancer_nulls = filter(lambda item: item[1] > 0, not_cancer.isnull().sum().items())\n",
    "print('Columns with null values for non-cancerous patients:')\n",
    "for tup in not_cancer_nulls:\n",
    "    print(f'Column: {tup[0]}, No. of Nulls: {tup[1]}, As a %: {round(tup[1]/len(cancer[tup[0]]), 2)}')\n",
    "    \n",
    "# Identify columns with null values for cancerous patients\n",
    "cancer_nulls = filter(lambda item: item[1] > 0, cancer.isnull().sum().items())\n",
    "print('\\nColumns with null values for cancerous patients:')\n",
    "for tup in cancer_nulls:\n",
    "    print(f'Column: {tup[0]}, No. of Nulls: {tup[1]}, As a %: {round(tup[1]/len(cancer[tup[0]]), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c3c95",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9161d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the categorical (nominal) features\n",
    "categorical_features = skin_cancer_df.select_dtypes(include=['object', 'category', 'string']).columns.tolist()\n",
    "\n",
    "# Impute and encode values in categorical columns\n",
    "updated_features = []\n",
    "for feature in categorical_features:\n",
    "    \n",
    "    # Impute null values in categorical features with the mode\n",
    "    skin_cancer_df[feature] = skin_cancer_df[feature].fillna(skin_cancer_df[feature].mode()[0])\n",
    "    \n",
    "    # Apply one-hot encoding to categorical (nominal) variables\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoded_feature = encoder.fit_transform(skin_cancer_df[[feature]])\n",
    "    \n",
    "    # Add the encoded columns to the dataframe\n",
    "    encoded_col_names = [f\"{feature}_{cat}\" for cat in encoder.categories_[0]]\n",
    "    encoded_feature_df = pd.DataFrame(encoded_feature, columns=encoded_col_names, index=skin_cancer_df.index)\n",
    "    skin_cancer_df = pd.concat([skin_cancer_df, encoded_feature_df], axis=1)\n",
    "    updated_features += encoded_col_names\n",
    "    \n",
    "# Remove unencoded categorical columns\n",
    "skin_cancer_df = skin_cancer_df.drop(columns=categorical_features)\n",
    "updated_cols = skin_cancer_df.columns\n",
    " \n",
    "# Use KNN to impute null values in the numerical columns\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputed_array = imputer.fit_transform(skin_cancer_df)\n",
    "skin_cancer_df = pd.DataFrame(imputed_array, columns=updated_cols, index=skin_cancer_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cd266b",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4951a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 14 New Features During Feature Engineering\n"
     ]
    }
   ],
   "source": [
    "# choosing which features to use from feature engineering\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Creates new features to help the model evaluate the ABCD factors used by dermatologists\n",
    "    :param df: a dataframe to add new features to\n",
    "    :return: the input dataframe with updated features\n",
    "    \"\"\"\n",
    "    og_cols = len(df.columns)\n",
    "    # A - Asymmetry, Border irregularity/bluriness, and Diameter (skin cancer diameter usually > 6 mm)\n",
    "    df['diameter_ratio'] = df['tbp_lv_minorAxisMM'] / df['clin_size_long_diam_mm']\n",
    "    df['area_irregularity'] = np.abs((np.pi * (df['clin_size_long_diam_mm'] / 2)**2) - (df['tbp_lv_areaMM2'])**(1/2))\n",
    "    df['perimeter_irregularity'] = np.abs((np.pi * df['clin_size_long_diam_mm']) - df['tbp_lv_perimeterMM'])\n",
    "    df['area_perimeter_ratio'] = df['tbp_lv_areaMM2'] / (df['tbp_lv_perimeterMM'] ** 2)\n",
    "    df['large_diameter'] = [1 if val > 5.5 else 0 for val in df['clin_size_long_diam_mm']] # skin cancer diameters tend to be larger than 6 mm\n",
    "    df['perimeter_to_area'] = (df['tbp_lv_perimeterMM']**2) / df['tbp_lv_areaMM2']\n",
    "    df['avg_normalized_irregularity'] = (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"]) / 2\n",
    "    \n",
    "    # Color (variation)  \n",
    "    df['hc_mean_contrast'] = ((df['tbp_lv_H'] + df['tbp_lv_Hext']) / 2) + ((df['tbp_lv_C'] + df['tbp_lv_Cext']) / 2)\n",
    "    df['tbp_lv_deltaH'] = np.abs(df['tbp_lv_H'] - df['tbp_lv_Hext'])\n",
    "    df['tbp_lv_deltaC'] = np.abs(df['tbp_lv_C'] + df['tbp_lv_Cext'])\n",
    "    df['overall_lab_contrast'] = np.sqrt(df['tbp_lv_deltaL']**2 + df['tbp_lv_deltaA']**2 + df['tbp_lv_deltaB']**2)\n",
    "    df['large_color_variance'] = [1 if val > 4 else 0 for val in df['tbp_lv_color_std_mean']]\n",
    "    df['average_lab_contrast'] = (df['tbp_lv_deltaL'] + df['tbp_lv_deltaA'] + df['tbp_lv_deltaB']) / 3\n",
    "    \n",
    "    # Features to maximize other features\n",
    "    df['lesion_location'] = np.sqrt(df['tbp_lv_x']**2 + df['tbp_lv_y']**2 + df['tbp_lv_z']**2) # l2 norm of lesion coordinates\n",
    "    print(f'Created {len(df.columns) - og_cols} New Features During Feature Engineering')\n",
    "    df = df.drop(['tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z'], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "skin_cancer_enhanced = create_features(skin_cancer_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda0a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe use these features in feature engineering\n",
    "\n",
    "def create_new_features(df):\n",
    "    # Create new features\n",
    "    df[\"color_uniformity\"] = np.where(df[\"tbp_lv_radial_color_std_max\"] == 0, 0, (df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_radial_color_std_max\"]))\n",
    "    df[\"size_age_interaction\"] = df[\"clin_size_long_diam_mm\"] * df[\"age_approx\"]\n",
    "    \n",
    "    df[\"log_lesion_area\"] = np.log(df[\"tbp_lv_areaMM2\"] + 1)\n",
    "    df[\"mean_hue_difference\"] = (df[\"tbp_lv_H\"] + df[\"tbp_lv_Hext\"]) / 2\n",
    "\n",
    "    return df\n",
    "\n",
    "skin_cancer_enhanced = create_new_features(skin_cancer_enhanced.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d774b4-e842-464c-b9b1-735187206cd1",
   "metadata": {},
   "source": [
    "# Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5273c102-4575-4bce-abb6-c1461a9e4f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 31 Features with High Correlation to Another Feature\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation matrix\n",
    "og_cols = len(skin_cancer_enhanced.columns)\n",
    "corr_matrix = skin_cancer_enhanced.corr().abs()\n",
    "\n",
    "# Remove repetitions by only keeping values in upper, right triangle\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Drop features with correlations to other features greater than 0.8\n",
    "threshold = 0.8\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "skin_cancer_enhanced = skin_cancer_enhanced.drop(to_drop, axis=1)\n",
    "print(f'Removed {og_cols - len(skin_cancer_enhanced.columns)} Features with High Correlation to Another Feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed6fa1-c51e-4498-906c-4a9269950edb",
   "metadata": {},
   "source": [
    "# Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149cde8a-2d87-4d7c-b216-cf5f13727be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importances using ANOVA f-test\n",
    "fs = SelectKBest(score_func=f_classif, k='all')\n",
    "skin_cancer_array = fs.fit_transform(skin_cancer_enhanced.drop(['target', 'image_path'], axis=1), skin_cancer_enhanced['target'])\n",
    "use_cols = skin_cancer_enhanced.drop(['target', 'image_path'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a9403-c75a-4095-b48a-d46d734b2da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar([use_cols[i] for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b69d8e8",
   "metadata": {},
   "source": [
    "# Aggregate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a342777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine enhanced metadata and image features into one data set\n",
    "images_features = pd.DataFrame(images_features)\n",
    "skin_cancer_features = skin_cancer_enhanced.drop('target', axis=1)\n",
    "skin_cancer_full = pd.concat([skin_cancer_features.reset_index(), images_features], axis=1)\n",
    "skin_cancer_full.columns = skin_cancer_full.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8878def9",
   "metadata": {},
   "source": [
    "# Isolation Forest - gives worse results than autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d67f2b8f-e450-4b6c-a5bb-a1e8c0f4aff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huebscher.m/.local/lib/python3.8/site-packages/imblearn/over_sampling/_smote/base.py:370: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S.S.: 0.21, Estimators: 60, f1_score: 0.42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.79      0.84    400666\n",
      "         1.0       0.35      0.53      0.42     84139\n",
      "\n",
      "    accuracy                           0.74    484805\n",
      "   macro avg       0.62      0.66      0.63    484805\n",
      "weighted avg       0.79      0.74      0.76    484805\n",
      "\n",
      "\n",
      "S.S.: 0.21, Estimators: 70, f1_score: 0.43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.79      0.84    400666\n",
      "         1.0       0.35      0.55      0.43     84139\n",
      "\n",
      "    accuracy                           0.75    484805\n",
      "   macro avg       0.62      0.67      0.63    484805\n",
      "weighted avg       0.80      0.75      0.77    484805\n",
      "\n",
      "\n",
      "S.S.: 0.21, Estimators: 90, f1_score: 0.44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.79      0.84    400666\n",
      "         1.0       0.36      0.57      0.44     84139\n",
      "\n",
      "    accuracy                           0.75    484805\n",
      "   macro avg       0.63      0.68      0.64    484805\n",
      "weighted avg       0.80      0.75      0.77    484805\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huebscher.m/.local/lib/python3.8/site-packages/imblearn/over_sampling/_smote/base.py:370: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S.S.: 0.23, Estimators: 70, f1_score: 0.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.77      0.83    400666\n",
      "         1.0       0.37      0.58      0.45     92153\n",
      "\n",
      "    accuracy                           0.73    492819\n",
      "   macro avg       0.63      0.68      0.64    492819\n",
      "weighted avg       0.79      0.73      0.75    492819\n",
      "\n",
      "\n",
      "S.S.: 0.23, Estimators: 90, f1_score: 0.46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.77      0.83    400666\n",
      "         1.0       0.37      0.59      0.46     92153\n",
      "\n",
      "    accuracy                           0.74    492819\n",
      "   macro avg       0.63      0.68      0.64    492819\n",
      "weighted avg       0.79      0.74      0.76    492819\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-72a065c0a522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Evaluate the models performance on testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mcr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mf1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf1_score\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     )\n\u001b[1;32m    213\u001b[0m                 ):\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2547\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2548\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2549\u001b[0m         \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Check that we don't mix label format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mys_types\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Check that we don't mix label format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mys_types\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;31m# Check multiclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0mfirst_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_row\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;31m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36munique_values\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best = (0, 0, 0, None)\n",
    "for ss in [x*0.01 for x in range(21, 33, 2)]:\n",
    "    # Oversample the minority group to make the data more balanced\n",
    "    smote = SMOTE(sampling_strategy=ss, random_state=42, n_jobs=3)\n",
    "    X_resampled, y_resampled = smote.fit_resample(skin_cancer_full.drop('isic_id', axis=1), skin_cancer_df['target'])\n",
    "\n",
    "    # Split the data - training is non-cancerous, test is on all patients to detect anomalies\n",
    "    X_train = X_resampled[y_resampled == 0]\n",
    "    X_test = X_resampled\n",
    "\n",
    "    # Scale the data between 0 and 1\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Develop and train the Isolation Forest model\n",
    "    c = len(y_resampled[y_resampled == 1]) / len(y_resampled[y_resampled == 0])\n",
    "    for estimators in range(60, 120, 10):\n",
    "        isf = IsolationForest(n_estimators=estimators, contamination=c, random_state=42)\n",
    "        isf.fit(X_train)\n",
    "\n",
    "        # Predict the targets for the test data\n",
    "        preds = isf.predict(X_test)\n",
    "        y_preds = [1 if p == -1 else 0 for p in preds]\n",
    "\n",
    "        # Evaluate the models performance on testing data\n",
    "        cr = classification_report(y_resampled, y_preds)\n",
    "        f1_score = float(cr.split()[12])\n",
    "        if f1_score > best[2]:\n",
    "            best = (ss, estimators, f1_score, cr)\n",
    "            print(f'\\nS.S.: {ss}, Estimators: {estimators}, f1_score: {f1_score}')\n",
    "            print(cr)\n",
    "print('Best Hyperparameters + result:', best[:2], '\\n', best[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46692e4a",
   "metadata": {},
   "source": [
    "# Autoencoder - best when dropout is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28abc06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0022 - val_loss: 2.5900e-04\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 2.0804e-04 - val_loss: 2.8170e-04\n",
      "Epoch 3/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 8.6720e-04 - val_loss: 1.1256e-04\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 1.3901e-04 - val_loss: 1.0572e-04\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 1.3141e-04 - val_loss: 6.2773e-05\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0027 - val_loss: 5.5272e-05\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 1.2240e-04 - val_loss: 4.8739e-05\n",
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 2.5014e-04 - val_loss: 5.3878e-05\n",
      "Epoch 9/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 1.7224e-04 - val_loss: 4.2633e-05\n",
      "Epoch 10/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0036 - val_loss: 2.0420e-04\n",
      "Epoch 11/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 6.8754e-05 - val_loss: 3.2494e-05\n",
      "Epoch 12/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 1.5248e-04 - val_loss: 0.0058\n",
      "Epoch 13/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 14/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 6.9377e-04 - val_loss: 0.0025\n",
      "Epoch 15/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 6.2512e-04 - val_loss: 4.3118e-04\n",
      "Epoch 16/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 17/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 7.3065e-04 - val_loss: 4.7516e-05\n",
      "Epoch 18/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 3.8911e-04 - val_loss: 3.3602e-05\n",
      "Epoch 19/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 2.4658e-04 - val_loss: 0.0060\n",
      "Epoch 20/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 21/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0016 - val_loss: 0.0055\n",
      "13147/13147 [==============================] - 16s 1ms/step\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.0, Threshold: 97, Best Epoch 11 f1 score: 0.77\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99    400666\n",
      "         1.0       0.99      0.62      0.77     20033\n",
      "\n",
      "    accuracy                           0.98    420699\n",
      "   macro avg       0.99      0.81      0.88    420699\n",
      "weighted avg       0.98      0.98      0.98    420699\n",
      "\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.0, Threshold: 98, Best Epoch 11 f1 score: 0.59\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.99    400666\n",
      "         1.0       0.99      0.42      0.59     20033\n",
      "\n",
      "    accuracy                           0.97    420699\n",
      "   macro avg       0.98      0.71      0.79    420699\n",
      "weighted avg       0.97      0.97      0.97    420699\n",
      "\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.0, Threshold: 99, Best Epoch 11 f1 score: 0.35\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98    400666\n",
      "         1.0       1.00      0.21      0.35     20033\n",
      "\n",
      "    accuracy                           0.96    420699\n",
      "   macro avg       0.98      0.60      0.66    420699\n",
      "weighted avg       0.96      0.96      0.95    420699\n",
      "\n",
      "Epoch 1/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0074 - val_loss: 0.0027\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 28s 2ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 3/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 9/100\n",
      " 4464/11269 [==========>...................] - ETA: 15s - loss: 0.0026"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-95e3a2a68488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Train the autoencoder using only the non-cancerous patients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         history = autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, validation_split=0.1,\n\u001b[0m\u001b[1;32m     39\u001b[0m                                  callbacks=[early_stopping])\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning - training on non-cancerous patients, w feature engineering\n",
    "best = (0, 0, 0, None)\n",
    "# Oversample the minority group to make the data more balanced\n",
    "for ss in range(5, 35, 10):\n",
    "    smote = SMOTE(sampling_strategy=ss*0.01, random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(skin_cancer_enhanced.drop('target', axis=1), skin_cancer_df['target'])\n",
    "\n",
    "    # Split the data - training is non-cancerous, test is on all patients to detect anomalies\n",
    "    X_train = X_resampled[y_resampled == 0]\n",
    "    X_test = X_resampled\n",
    "\n",
    "    # Scale the data between 0 and 1\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Build the autoencoder model - dropout of 5 works best\n",
    "    for d in range(0, 10, 2):\n",
    "        \n",
    "        autoencoder = Sequential([\n",
    "            Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
    "            Dropout(d*0.1),  \n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(d*0.1),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(d*0.1),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(d*0.1),\n",
    "            Dense(X_train.shape[1], activation='sigmoid')  # Output layer should match input\n",
    "        ])\n",
    "\n",
    "        autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "        # Train the autoencoder using only the non-cancerous patients\n",
    "        history = autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, validation_split=0.1,\n",
    "                                 callbacks=[early_stopping])\n",
    "\n",
    "        # Find the epoch with the lowest validation loss\n",
    "        best_epoch = np.argmin(history.history['val_loss']) + 1  # Add 1 since epochs are 1-indexed\n",
    "        best_val_loss = np.min(history.history['val_loss'])\n",
    "\n",
    "        # Calculate reconstruction error for each sample\n",
    "        reconstructed = autoencoder.predict(X_test)\n",
    "        reconstruction_error = np.mean(np.abs(reconstructed - X_test), axis=1)\n",
    "\n",
    "        # Threshold the reconstruction error to detect anomalies\n",
    "        for thresh in range(97, 100):\n",
    "            threshold = np.percentile(reconstruction_error, thresh)  # Set threshold (e.g., 99th percentile)\n",
    "            predictions_autoencoder = (reconstruction_error > threshold).astype(int)  # 1 = anomaly (cancer), 0 = normal\n",
    "            cr = classification_report(y_resampled, predictions_autoencoder)\n",
    "            f1_score = float(cr.split()[12])\n",
    "            print(f'\\nS.S.: {ss*.01}, Dropout: {d*.1}, Threshold: {thresh}, Best Epoch {best_epoch}',\n",
    "                  f'f1 score: {f1_score}\\n', cr)\n",
    "            if f1_score > best[2]:\n",
    "                best = (ss, d, thresh, best_epoch, f1_score, cr)\n",
    "\n",
    "print('Best:')\n",
    "print(best[:4])\n",
    "print(best[5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
