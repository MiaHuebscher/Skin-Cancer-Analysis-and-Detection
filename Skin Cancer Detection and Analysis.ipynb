{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a54bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "import os\n",
    "import keras\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from io import BytesIO\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications import EfficientNetV2M\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Activation, Input, Conv2D, Multiply, Reshape\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.utils import Sequence\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed058f-8682-4c61-815c-1bcb643be5a4",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d4bdf8-915c-4442-835f-c95c493d882f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(undersample_strat=0.07):\n",
    "    \"\"\"\n",
    "    Returns the metadata and image generators for training and validation\n",
    "    :param undersample_strat: the desired proportion of cancerous to non-cancerous lesions in the dataset\n",
    "    \"\"\"\n",
    "    # Extract zipped data to a local directory, if not done already\n",
    "    if not os.path.isdir('Data'):\n",
    "        with zipfile.ZipFile('anon-patient-data.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall('Data')\n",
    "        \n",
    "    # Load the metadata\n",
    "    skin_cancer_df = pd.read_csv('Data/train-metadata.csv', low_memory=False, usecols=[num for num in range(0, 43) if num not in [2, 7]], index_col='isic_id')\n",
    "        \n",
    "    # Randomly undersample the cancer-free lesions in the dataset to enhance performance time and address class imbalance\n",
    "    rus = RandomUnderSampler(random_state=42, sampling_strategy=undersample_strat)\n",
    "    (skin_cancer_df, targets) = rus.fit_resample(skin_cancer_df.drop('target', axis=1), skin_cancer_df['target'])\n",
    "    \n",
    "    # Add an image path column and turn targets into binary strings\n",
    "    skin_cancer_df['image_filepath'] = ['Data/image/' + img_id + '.jpg' for img_id in skin_cancer_df.index]\n",
    "    skin_cancer_df['target'] = targets.astype(str)\n",
    "    \n",
    "    # Initialize ImageDataGenerators for testing and validation\n",
    "    train_df, val_df = train_test_split(skin_cancer_df, test_size=0.3, stratify=targets, random_state=42)\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, \n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True)\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Create training and validation generators from their respective datasets\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=None,\n",
    "        x_col='image_filepath',\n",
    "        y_col='target',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "    val_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        directory=None,\n",
    "        x_col='image_filepath',\n",
    "        y_col='target',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "    \n",
    "    # Turn the targets back to integers\n",
    "    skin_cancer_df['target'] = targets.astype(int)\n",
    "    \n",
    "    return skin_cancer_df.drop('image_filepath', axis=1), train_generator, val_generator\n",
    "\n",
    "def extract_image_features(train_generator, val_generator):\n",
    "    \"\"\"\n",
    "    Trains a ResNet50 model to extract features from images of skin lesions\n",
    "    \n",
    "    :param train_generator: stores augmented images for training\n",
    "    :param val_generator: stores scaled images for validation\n",
    "    \"\"\"\n",
    "    # Load ResNet50 with pre-trained ImageNet weights\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Freeze lower layers and allow fine-tuning on upper layers\n",
    "    for layer in base_model.layers[:int(len(base_model.layers) * 0.3)]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Add global pooling and temporary classification layers for fine-tuning\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(512, activation='relu', kernel_regularizer=l2(0.04), name='fc1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = Dropout(0.1, name='dropout1')(x)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.04), name='fc2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = Dropout(0.1, name='dropout2')(x)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.04), name='fc3')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = Dropout(0.1, name='dropout3')(x)\n",
    "    output = Dense(1, activation='sigmoid', name='output')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    # Initialize loss and callback functions\n",
    "    #loss = WeightedBinaryCrossentropy(weight_zero=1.0, weight_one=2.0)\n",
    "    early_stopping = EarlyStopping(monitor='val_recall', patience=8, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_recall', factor=0.1, patience=5, min_lr=0.001)\n",
    "    \n",
    "    # Compile and train the model\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', \n",
    "                  metrics=[keras.metrics.TruePositives(name='true_positives'), keras.metrics.Recall(name='recall'), \n",
    "                           keras.metrics.SpecificityAtSensitivity(sensitivity=0.8, name='specificity_at_sensitivity'), BinaryCrossentropy(name='BinaryCrossentropy')])\n",
    "    history = model.fit(train_generator, validation_data=val_generator, epochs=20, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "    # Use trained model to extract image features \n",
    "    feature_extractor = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "    train_features = GlobalAveragePooling2D()(base_model.predict(train_generator, verbose=1))\n",
    "    val_features = GlobalAveragePooling2D()(base_model.predict(val_generator, verbose=1))\n",
    "    images_features = np.vstack([train_features, val_features])\n",
    "\n",
    "    return images_features, history, base_model\n",
    "\n",
    "def plot_history(history, fig_name):\n",
    "    \"\"\"\n",
    "    Plots the trianing and validation performance across epochs and various metrics\n",
    "    \"\"\"\n",
    "    # Initialize variables required to plot series of charts\n",
    "    plt.figure(figsize=(18, 16))\n",
    "    num_plots = int(len(list(history.history.keys())[:-1]) / 2)\n",
    "    if num_plots % 2 == 0:\n",
    "        num_rows = num_plots / 2\n",
    "    else:\n",
    "        num_rows = (num_plots + 1) / 2\n",
    "    all_metrics = list(history.history.keys())[:num_plots]\n",
    "    \n",
    "    # Plot training & validation performance for every metrics\n",
    "    for p in range(num_plots):\n",
    "        metric = all_metrics[p]\n",
    "        plt.subplot(num_rows, 2, p + 1)\n",
    "        plt.plot(history.history[metric], label=f'Training {metric}')\n",
    "        plt.plot(history.history[f'val_{metric}'], label=f'Validation {metric}')\n",
    "        plt.title(f'Training and Validation {metric}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend()\n",
    "        \n",
    "    # Save the figure\n",
    "    plt.savefig(fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06cd01-a6eb-49b8-a14c-64476601d505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4204 validated image filenames belonging to 2 classes.\n",
      "Found 1803 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "132/132 [==============================] - 517s 4s/step - loss: 53.4092 - true_positives: 163.0000 - recall: 0.5927 - specificity_at_sensitivity: 0.2739 - BinaryCrossentropy: 0.8462 - val_loss: 52.1875 - val_true_positives: 0.0000e+00 - val_recall: 0.0000e+00 - val_specificity_at_sensitivity: 0.0861 - val_BinaryCrossentropy: 0.3296 - lr: 1.0000e-05\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 500s 4s/step - loss: 51.9891 - true_positives: 176.0000 - recall: 0.6400 - specificity_at_sensitivity: 0.3085 - BinaryCrossentropy: 0.8067 - val_loss: 51.8015 - val_true_positives: 118.0000 - val_recall: 1.0000 - val_specificity_at_sensitivity: 0.1614 - val_BinaryCrossentropy: 1.2976 - lr: 1.0000e-05\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 500s 4s/step - loss: 50.6192 - true_positives: 177.0000 - recall: 0.6436 - specificity_at_sensitivity: 0.3347 - BinaryCrossentropy: 0.7828 - val_loss: 49.4493 - val_true_positives: 10.0000 - val_recall: 0.0847 - val_specificity_at_sensitivity: 0.2908 - val_BinaryCrossentropy: 0.2939 - lr: 1.0000e-05\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 512s 4s/step - loss: 49.2430 - true_positives: 178.0000 - recall: 0.6473 - specificity_at_sensitivity: 0.3851 - BinaryCrossentropy: 0.7557 - val_loss: 48.1430 - val_true_positives: 22.0000 - val_recall: 0.1864 - val_specificity_at_sensitivity: 0.2142 - val_BinaryCrossentropy: 0.3265 - lr: 1.0000e-05\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 528s 4s/step - loss: 47.8990 - true_positives: 178.0000 - recall: 0.6473 - specificity_at_sensitivity: 0.3655 - BinaryCrossentropy: 0.7415 - val_loss: 48.0674 - val_true_positives: 108.0000 - val_recall: 0.9153 - val_specificity_at_sensitivity: 0.3828 - val_BinaryCrossentropy: 1.5762 - lr: 1.0000e-05\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 514s 4s/step - loss: 46.5661 - true_positives: 190.0000 - recall: 0.6909 - specificity_at_sensitivity: 0.4019 - BinaryCrossentropy: 0.7255 - val_loss: 46.7857 - val_true_positives: 115.0000 - val_recall: 0.9746 - val_specificity_at_sensitivity: 0.3757 - val_BinaryCrossentropy: 1.6058 - lr: 1.0000e-05\n",
      "Epoch 7/20\n",
      "132/132 [==============================] - 531s 4s/step - loss: 45.2427 - true_positives: 166.0000 - recall: 0.6036 - specificity_at_sensitivity: 0.3696 - BinaryCrossentropy: 0.7129 - val_loss: 44.2476 - val_true_positives: 17.0000 - val_recall: 0.1441 - val_specificity_at_sensitivity: 0.3537 - val_BinaryCrossentropy: 0.3679 - lr: 1.0000e-05\n",
      "Epoch 8/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 43.9338 - true_positives: 185.0000 - recall: 0.6727 - specificity_at_sensitivity: 0.3739 - BinaryCrossentropy: 0.6992"
     ]
    }
   ],
   "source": [
    "# Load the image features and metadata\n",
    "skin_cancer_df, train_generator, val_generator = load_data(undersample_strat=0.07)\n",
    "images_features, resnet_history, feature_extractor = extract_image_features(train_generator, val_generator)\n",
    "pd.DataFrame(images_features).to_csv('resnet50_features.csv', index=False, header=False)\n",
    "\n",
    "# Plot and save the loss history\n",
    "plot_history(resnet_history, 'ResNet50 Performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded8fa8-355f-438d-9396-1768d954cbc8",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of Metadata by Lesion Type (Cancer vs Non-Cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaf24b9-b4c6-4057-892d-28a4d03030e4",
   "metadata": {},
   "source": [
    "### How balanced is the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd2928-db81-494a-8868-ab14f0cc2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the number of cancerous vs non-cancerous lesions in the data\n",
    "not_cancer = skin_cancer_df[skin_cancer_df['target'] == 0]\n",
    "cancer = skin_cancer_df[skin_cancer_df['target'] == 1]\n",
    "print(f'Out of the {len(skin_cancer_df)} lesions in our dataset, {len(not_cancer)} are not cancerous and {len(cancer)} are cancerous.')\n",
    "\n",
    "# Visualize the results in a pie chart\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie([len(not_cancer), len(cancer)], labels=['Not Cancer', 'Cancer'], autopct='%1.1f%%')\n",
    "ax.set_title('Proportion of Cancerous vs Non-Cancerous Lesions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98afe0bc-a75e-488f-992f-1fb90cd1cb6f",
   "metadata": {},
   "source": [
    "#### The data is heavily imbalanced, with almost all available lesions being non-cancerous. This characteristic of the data is our primary motivator for utilizing anomaly detection rather than binary classification as our method for cancer detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6135be-ced6-4818-8c92-ff25335dd8e6",
   "metadata": {},
   "source": [
    "### Do men and women make up different proportions of cancerous vs non-cancerous lesions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759724c1-203b-443c-b12f-f24dc9e97e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the frequencies of each sex for cancerous and non-cancerous lesions\n",
    "gender_freqs_cancer = Counter(cancer['sex'])\n",
    "gender_freqs_noncancer = Counter(not_cancer['sex'])\n",
    "\n",
    "# Visualize the frequencies\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].pie([gender_freqs_noncancer['male'], gender_freqs_noncancer['female'], gender_freqs_noncancer[np.nan]],\n",
    "       labels=['male', 'female', 'NA'], autopct='%1.1f%%')\n",
    "ax[0].set_title('Non-Cancerous Patients')\n",
    "ax[1].pie([gender_freqs_cancer['male'], gender_freqs_cancer['female'], gender_freqs_cancer[np.nan]],\n",
    "       labels=['male', 'female', 'NA'], autopct='%1.1f%%')\n",
    "ax[1].set_title('Cancerous Patients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36365eb6-8c83-42a8-867f-688ea24bce43",
   "metadata": {},
   "source": [
    "#### Men are more represented in cancerous lesions than non-cancerous lesions, which aligns with the notion that men are more likely to obtain skin cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9d5c89-7c82-4499-b262-c3f050b808a0",
   "metadata": {},
   "source": [
    "### Is there a significant difference in the age distribution for cancerous vs non-cancerous patients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578bb0cc-efaa-447e-9e8b-fd6da0a3a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the age distributions\n",
    "plt.hist(cancer['age_approx'], histtype='step', color='red', density=True, label='Cancerous')\n",
    "plt.hist(not_cancer['age_approx'], histtype='step', color='green', density=True, label='Non-Cancerous')\n",
    "plt.legend()\n",
    "plt.xlabel('Age Approximations')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Age Distribution of Cancerous vs Non-Cancerous Patients')\n",
    "plt.show()\n",
    "\n",
    "# Perform the Mann-Whitney U test\n",
    "u_stat, p_value = stats.mannwhitneyu(cancer['age_approx'], not_cancer['age_approx'])\n",
    "\n",
    "# Print the result\n",
    "print(f'Mann-Whitney U test: U-stat = {u_stat}, p-value = {p_value}')\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print('There is a significant difference in the age distribution between cancerous and non-cancerous patients.')\n",
    "else:\n",
    "    print('There is no significant difference in the age distribution between cancerous and non-cancerous patients.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312f25af-0b8b-46ad-8ef3-308ca6249774",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c1bd2-729e-4ff3-bbf7-1792952575a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to compare summary stats for (choose columns that align with the ABCD factors used for skin cancer detection)\n",
    "use_cols = ['tbp_lv_symm_2axis', 'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean', 'clin_size_long_diam_mm']\n",
    "\n",
    "# Present summary statistics for cancerous patients\n",
    "cancer[use_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dfd094-e95c-4bd2-bec5-fb26588fd57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Present summary statistics for non-cancerous patients\n",
    "not_cancer[use_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d6cb8-bd14-4daa-ad13-380d15ec245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Mann-Whitney U test to determine if any of these differences are significant\n",
    "for col in use_cols:\n",
    "    u_stat, p_value = stats.mannwhitneyu(cancer[col], not_cancer[col])\n",
    "    if p_value < 0.05:\n",
    "        print(f'There is a significant difference in {col} between cancerous and non-cancerous patients.')\n",
    "    else:\n",
    "        print(f'There is no significant difference in {col} between cancerous and non-cancerous patients.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65023dfd-22e5-481f-bbb1-31bbd0f6c0e2",
   "metadata": {},
   "source": [
    "### Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bdff5d-9df6-4fae-b02d-ac13d4c99725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with null values for non-cancerous patients\n",
    "not_cancer_nulls = filter(lambda item: item[1] > 0, not_cancer.isnull().sum().items())\n",
    "print('Columns with null values for non-cancerous patients:')\n",
    "for tup in not_cancer_nulls:\n",
    "    print(f'Column: {tup[0]}, No. of Nulls: {tup[1]}, As a %: {round(tup[1]/len(cancer[tup[0]]), 2)}')\n",
    "    \n",
    "# Identify columns with null values for cancerous patients\n",
    "cancer_nulls = filter(lambda item: item[1] > 0, cancer.isnull().sum().items())\n",
    "print('\\nColumns with null values for cancerous patients:')\n",
    "for tup in cancer_nulls:\n",
    "    print(f'Column: {tup[0]}, No. of Nulls: {tup[1]}, As a %: {round(tup[1]/len(cancer[tup[0]]), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c3c95",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the categorical (nominal) features\n",
    "skin_cancer_prepro = skin_cancer_df.copy()\n",
    "categorical_features = skin_cancer_prepro.select_dtypes(include=['object', 'category', 'string']).columns.tolist()\n",
    "\n",
    "# Impute and encode values in categorical columns\n",
    "for feature in categorical_features:\n",
    "    \n",
    "    # Impute null values in categorical features with the mode\n",
    "    skin_cancer_prepro[feature] = skin_cancer_prepro[feature].fillna(skin_cancer_prepro[feature].mode()[0])\n",
    "    \n",
    "    # Apply one-hot encoding to categorical (nominal) variables\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoded_feature = encoder.fit_transform(skin_cancer_prepro[[feature]])\n",
    "    \n",
    "    # Add the encoded columns to the dataframe\n",
    "    encoded_col_names = [f\"{feature}_{cat}\" for cat in encoder.categories_[0]]\n",
    "    encoded_feature_df = pd.DataFrame(encoded_feature, columns=encoded_col_names, index=skin_cancer_prepro.index)\n",
    "    skin_cancer_prepro = pd.concat([skin_cancer_prepro, encoded_feature_df], axis=1)\n",
    "    \n",
    "# Remove unencoded categorical columns\n",
    "skin_cancer_prepro = skin_cancer_prepro.drop(columns=categorical_features)\n",
    "updated_cols = skin_cancer_prepro.columns\n",
    " \n",
    "# Use KNN to impute null values in the numerical columns\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputed_array = imputer.fit_transform(skin_cancer_prepro)\n",
    "skin_cancer_prepro = pd.DataFrame(imputed_array, columns=updated_cols, index=skin_cancer_prepro.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cd266b",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4951a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Creates new features to help the model evaluate the ABCD factors used by dermatologists\n",
    "    :param df: a dataframe to add new features to\n",
    "    :return: the input dataframe with updated features\n",
    "    \"\"\"\n",
    "    og_cols = len(df.columns)\n",
    "    # A - Asymmetry, Border irregularity/bluriness, and Diameter (skin cancer diameter usually > 6 mm)\n",
    "    df['diameter_ratio'] = df['tbp_lv_minorAxisMM'] / df['clin_size_long_diam_mm']\n",
    "    df['area_irregularity'] = np.abs((np.pi * (df['clin_size_long_diam_mm'] / 2)**2) - (df['tbp_lv_areaMM2'])**(1/2))\n",
    "    df['perimeter_irregularity'] = np.abs((np.pi * df['clin_size_long_diam_mm']) - df['tbp_lv_perimeterMM'])\n",
    "    df['area_perimeter_ratio'] = df['tbp_lv_areaMM2'] / (df['tbp_lv_perimeterMM'] ** 2)\n",
    "    df['large_diameter'] = [1 if val > 6 else 0 for val in df['clin_size_long_diam_mm']] # skin cancer diameters tend to be larger than 6 mm\n",
    "    df['perimeter_to_area'] = (df['tbp_lv_perimeterMM']**2) / df['tbp_lv_areaMM2']\n",
    "    df['avg_normalized_irregularity'] = (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"]) / 2\n",
    "    \n",
    "    # Color (variation)  \n",
    "    df['hc_mean_contrast'] = ((df['tbp_lv_H'] + df['tbp_lv_Hext']) / 2) + ((df['tbp_lv_C'] + df['tbp_lv_Cext']) / 2)\n",
    "    df['tbp_lv_deltaH'] = np.abs(df['tbp_lv_H'] - df['tbp_lv_Hext'])\n",
    "    df['tbp_lv_deltaC'] = np.abs(df['tbp_lv_C'] + df['tbp_lv_Cext'])\n",
    "    df['overall_lab_contrast'] = np.sqrt(df['tbp_lv_deltaL']**2 + df['tbp_lv_deltaA']**2 + df['tbp_lv_deltaB']**2)\n",
    "    df['large_color_variance'] = [1 if val > 4 else 0 for val in df['tbp_lv_color_std_mean']]\n",
    "    df['average_lab_contrast'] = (df['tbp_lv_deltaL'] + df['tbp_lv_deltaA'] + df['tbp_lv_deltaB']) / 3\n",
    "    \n",
    "    # Features to maximize other features\n",
    "    df['lesion_location'] = np.sqrt(df['tbp_lv_x']**2 + df['tbp_lv_y']**2 + df['tbp_lv_z']**2) # l2 norm of lesion coordinates\n",
    "    print(f'Created {len(df.columns) - og_cols} New Features During Feature Engineering')\n",
    "    df = df.drop(['tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z'], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "skin_cancer_enhanced = create_features(skin_cancer_prepro.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c9a45-8e6a-4c5b-8373-7fdc44a1d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_cancer_enhanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed6fa1-c51e-4498-906c-4a9269950edb",
   "metadata": {},
   "source": [
    "# Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149cde8a-2d87-4d7c-b216-cf5f13727be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importances using mutual information classification\n",
    "fs = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "skin_cancer_array = fs.fit_transform(skin_cancer_enhanced.drop(['target'], axis=1), skin_cancer_enhanced['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a9403-c75a-4095-b48a-d46d734b2da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances\n",
    "plt.figure(figsize=(15,5))\n",
    "use_cols = skin_cancer_enhanced.drop(['target'], axis=1).columns\n",
    "plt.bar([use_cols[i] for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b69d8e8",
   "metadata": {},
   "source": [
    "# Aggregating Image Features and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine enhanced metadata and image features into one data set\n",
    "images_features = pd.DataFrame(images_features)\n",
    "skin_cancer_full = pd.concat([skin_cancer_enhanced.reset_index(drop=True), images_features], axis=1)\n",
    "skin_cancer_full.columns = skin_cancer_full.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89565000-4b59-4fd2-8258-aeab03f1cfb7",
   "metadata": {},
   "source": [
    "# Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f2b8f-e450-4b6c-a5bb-a1e8c0f4aff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best = (0, 0, 0, None)\n",
    "cancer = skin_cancer_full[skin_cancer_full['target']==1]\n",
    "no_cancer = skin_cancer_full[skin_cancer_full['target']==0]\n",
    "training, val_no_cancer = train_test_split(no_cancer, test_size=0.40, random_state=42)\n",
    "validation = pd.concat([val_no_cancer, cancer], axis=0)\n",
    "val_counter = Counter(validation['target'])\n",
    "print(f'Validation Data: {val_counter[1.0]} cancer, {val_counter[0.0]} not cancer, {round(val_counter[1.0] / val_counter[0.0]*100, 3)}%')\n",
    "\n",
    "# Scale the data between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(training.drop('target', axis=1))\n",
    "X_test = scaler.transform(validation.drop('target', axis=1))\n",
    "\n",
    "# Develop and train the Isolation Forest model\n",
    "for c in range(20, 51, 1):\n",
    "    print(c*0.01)\n",
    "    for estimators in range(70, 150, 10):\n",
    "        # Initialize and train the model\n",
    "        isf = IsolationForest(n_estimators=estimators, contamination=c*0.01, random_state=42)        \n",
    "        scores_prediction = isf.fit(X_train)\n",
    "\n",
    "        # Predict the targets for the test data\n",
    "        preds = isf.predict(X_test)\n",
    "        y_preds = [1 if p == -1 else 0 for p in preds]\n",
    "\n",
    "        # Evaluate the models performance on testing data\n",
    "        cr = classification_report(validation['target'], y_preds)\n",
    "        f1_score = float(cr.split()[12])\n",
    "        if f1_score > best[2]:\n",
    "            best = (estimators, c*0.01, f1_score, cr)\n",
    "            print(f'\\nEstimators: {estimators}, C: {c*0.01}, f1_score: {f1_score}')\n",
    "            print(cr)\n",
    "print('Best Hyperparameters + result:', best[:3], '\\n', best[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46692e4a",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae3887-041e-4658-9a66-98310bc19218",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable(name=\"weighted_bincrossentropy\")\n",
    "class WeightedBinaryCrossentropy(tf.keras.losses.Loss):\n",
    "    \"\"\"\n",
    "    A custom loss functions to address class imbalance\n",
    "    \"\"\"\n",
    "    def __init__(self, weight_zero=1.0, weight_one=2.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weight_zero = tf.constant(weight_zero, dtype=tf.float32)\n",
    "        self.weight_one = tf.constant(weight_one, dtype=tf.float32)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Returns the weighted binary crossentropy of two lists containing 1s and 0s\n",
    "        \"\"\"\n",
    "        # Ensure shapes and types are compatible\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n",
    "\n",
    "        # Compute weighted binary crossentropy\n",
    "        bin_crossentropy = -(y_true * tf.math.log(y_pred) + (1. - y_true) * tf.math.log(1. - y_pred))\n",
    "        weights = y_true * self.weight_one + (1. - y_true) * self.weight_zero\n",
    "        weighted_bin_crossentropy = weights * bin_crossentropy\n",
    "\n",
    "        return tf.reduce_mean(weighted_bin_crossentropy)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"weight_zero\": self.weight_zero.numpy(), \"weight_one\": self.weight_one.numpy()})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abc06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample minorty class using SMOTE\n",
    "best = (0,0,0,0, None)\n",
    "\n",
    "# Separate data into training and validation - train only on normal data and validate on mixed data\n",
    "cancer = skin_cancer_full[skin_cancer_full['target'] == 1]\n",
    "no_cancer = skin_cancer_full[skin_cancer_full['target'] == 0]\n",
    "training, val_no_cancer = train_test_split(no_cancer, test_size=0.4, random_state=42)\n",
    "validation = pd.concat([val_no_cancer, cancer], axis=0)\n",
    "\n",
    "# Scale data between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(training.drop('target', axis=1))\n",
    "X_val = scaler.fit_transform(validation.drop('target', axis=1))\n",
    "\n",
    "# Construct the autoencoder model\n",
    "for d in range(2, 6, 2):\n",
    "    best = (0,0,0,0, None)\n",
    "    autoencoder = Sequential([\n",
    "        # Encoder\n",
    "        Dense(1024, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        BatchNormalization(name='bn1'),\n",
    "        Dropout(d * 0.1),  \n",
    "        Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        BatchNormalization(name='bn2'),\n",
    "        Dropout(d * 0.1),  \n",
    "        Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        BatchNormalization(name='bn3'),\n",
    "        Dropout(d * 0.1),  \n",
    "        Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        BatchNormalization(name='bn4'),\n",
    "        \n",
    "        # Bottleneck (increased capacity)\n",
    "        Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        \n",
    "        # Decoder\n",
    "        Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        BatchNormalization(name='bn5'),\n",
    "        Dropout(d * 0.1),\n",
    "        Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        BatchNormalization(name='bn6'),\n",
    "        Dropout(d * 0.1),  \n",
    "        Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        BatchNormalization(name='bn7'),\n",
    "        Dense(1024, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        \n",
    "        # Output Layer\n",
    "        Dense(X_train.shape[1], activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    loss = WeightedBinaryCrossentropy(weight_zero=1.0, weight_one=20.0)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.0001), loss=[loss], metrics = [keras.metrics.Precision(name='precision'), keras.metrics.Recall(name='recall'), \n",
    "                                                                                    keras.metrics.TruePositives(name='true_positives'), keras.metrics.AUC(name='auc')])\n",
    "    early_stopping = EarlyStopping(monitor='val_recall', patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_recall', factor=0.1, patience=5, min_lr=0.001)\n",
    "\n",
    "\n",
    "    # Train the autoencoder using only the non-cancerous patients\n",
    "    autoencoder_history = autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "    # Find the epoch with the lowest validation loss\n",
    "    best_epoch = np.argmin(autoencoder_history.history['val_loss']) + 1\n",
    "    best_val_loss = np.min(autoencoder_history.history['val_loss'])\n",
    "\n",
    "    # Calculate reconstruction error for each sample\n",
    "    reconstructed = autoencoder.predict(X_val)\n",
    "    reconstruction_error = np.mean(np.abs(reconstructed - X_val), axis=1)\n",
    "    \n",
    "    # Identify the optimal threshold that maximizes the distance between TPR and FPR\n",
    "    fpr, tpr, thresholds = roc_curve(validation['target'], reconstruction_error)\n",
    "    optimal_threshold = thresholds[np.argmax(tpr - fpr)]\n",
    "    \n",
    "    predictions = (reconstruction_error > optimal_threshold).astype(int)\n",
    "        \n",
    "    cr = classification_report(validation['target'], predictions)\n",
    "    print(cr)\n",
    "    f1_score = float(cr.split()[12])  \n",
    "    \n",
    "    if f1_score > best[3]:\n",
    "        best = (d, optimal_threshold, best_epoch, f1_score, cr)\n",
    "\n",
    "print('Overall Best (d, tresh, best_epoch, f1_score, cr)')\n",
    "print(best[:4])\n",
    "print(best[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1d8b83-e5f1-4965-a48b-c785da42ae37",
   "metadata": {},
   "source": [
    "## Autoencoder Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55acf60-5bfe-4f44-a33f-0b738b1f4dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the autoencoder predictions against the true values\n",
    "plt.figure()\n",
    "colors = ['red' if p == 1.0 else 'green' for p in predictions]\n",
    "plt.title('Reconstruction Errors and Predictions against True Targets')\n",
    "plt.scatter(reconstruction_error, validation['target'], color=colors)\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('True Targets (1 - cancer, 0 - not cancer)')\n",
    "red_patch = mpatches.Patch(color='red', label='Cancer Prediction')\n",
    "green_patch = mpatches.Patch(color='green', label='Benign Prediction')\n",
    "plt.legend(handles=[red_patch, green_patch])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39053ac9-75b3-4fa6-ab44-b90fc4f47537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the ROC curve for the model's predictions\n",
    "fpr, tpr, thresholds = roc_curve(validation['target'], reconstruction_error)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Autoencoder Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f223b6-d804-4bfd-ae40-d8096763eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(autoencoder_history, 'Autoencoder Performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed6c544-7f48-4d7f-a835-e4ba87d71d81",
   "metadata": {},
   "source": [
    "# Simple Binary Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc3a02c-eb85-424d-bf0c-e9deb23b4547",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b75f674-3509-46a8-80d6-ec0d2d601187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the class weight to balanced increases sensitivity (recall) by double!\n",
    "lr = LogisticRegression(random_state=42, max_iter=800, class_weight='balanced')\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(skin_cancer_full.drop('target', axis=1), skin_cancer_full['target'], test_size=0.2, \n",
    "                                                    stratify=skin_cancer_full['target'], random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=0.1, stratify=y_rest, random_state=42)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "val_preds = lr.predict(X_val)\n",
    "test_preds = lr.predict(X_test)\n",
    "rest_preds = lr.predict(X_rest)\n",
    "\n",
    "rest_counter = Counter(y_rest)\n",
    "print(f'Validation Data: {rest_counter[1.0]} cancer, {rest_counter[0.0]} not cancer, {round(rest_counter[1.0] / rest_counter[0.0]*100, 3)}%')\n",
    "print('Validation Performance:\\n', classification_report(y_rest, rest_preds))\n",
    "\n",
    "val_counter = Counter(y_val)\n",
    "print(f'Validation Data: {val_counter[1.0]} cancer, {val_counter[0.0]} not cancer, {round(val_counter[1.0] / val_counter[0.0]*100, 3)}%')\n",
    "print('Validation Performance:\\n', classification_report(y_val, val_preds))\n",
    "\n",
    "test_counter = Counter(y_test)\n",
    "print(f'\\nTest Data: {test_counter[1.0]} cancer, {test_counter[0.0]} not cancer, {round(test_counter[1.0] / test_counter[0.0]*100, 3)}%')\n",
    "print('Test Performance:\\n', classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888553a-bb23-4faa-a4c1-cc95e0bc19f8",
   "metadata": {},
   "source": [
    "## CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d14265e-64d4-4a64-bd0b-2a04d9671ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CatBoostClassifier\n",
    "catboost_model = CatBoostClassifier(random_state=42,class_weights=[1, 2], iterations=1000, verbose=200)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(skin_cancer_full.drop('target', axis=1), skin_cancer_full['target'], \n",
    "                                                    test_size=0.2, stratify=skin_cancer_full['target'], random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=0.05, stratify=y_rest, random_state=42)\n",
    "\n",
    "# Train the CatBoost model and utilize it for predictions\n",
    "catboost_model.fit(X_train, y_train)\n",
    "val_preds = catboost_model.predict(X_val)\n",
    "test_preds = catboost_model.predict(X_test)\n",
    "rest_preds = catboost_model.predict(X_rest)\n",
    "\n",
    "# Print rest data performance\n",
    "rest_counter = Counter(y_rest)\n",
    "print(f'Validation Data: {rest_counter[1.0]} cancer, {rest_counter[0.0]} not cancer, {round(rest_counter[1.0] / rest_counter[0.0]*100, 3)}%')\n",
    "print('Validation Performance:\\n', classification_report(y_rest, rest_preds))\n",
    "\n",
    "# Print validation data performance\n",
    "val_counter = Counter(y_val)\n",
    "print(f'Validation Data: {val_counter[1.0]} cancer, {val_counter[0.0]} not cancer, {round(val_counter[1.0] / val_counter[0.0]*100, 3)}%')\n",
    "print('Validation Performance:\\n', classification_report(y_val, val_preds))\n",
    "\n",
    "# Print test data performance\n",
    "test_counter = Counter(y_test)\n",
    "print(f'\\nTest Data: {test_counter[1.0]} cancer, {test_counter[0.0]} not cancer, {round(test_counter[1.0] / test_counter[0.0]*100, 3)}%')\n",
    "print('Test Performance:\\n', classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d3c0f-962b-4237-bdee-df03ac66c84a",
   "metadata": {},
   "source": [
    "# Autoencoder and CatBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48541fc-111c-41b4-a5c2-39597cea1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializwe the catboost model and split the validation reconstruction errors into training and testing\n",
    "catboost_model = CatBoostClassifier(random_state=42,class_weights=[1, 2], iterations=1000, verbose=200)\n",
    "X_train, X_test, y_train, y_test = train_test_split(reconstruction_error.reshape(len(reconstruction_error), 1), validation['target'],\n",
    "                                                    test_size=0.2, stratify=validation['target'], random_state=42)\n",
    "\n",
    "# Determine the performance of the model on testing reconstruction error data\n",
    "catboost_model.fit(X_train, y_train)\n",
    "preds = catboost_model.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88376d21-d8f2-414f-80ac-68551cf178fd",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d01c252-65d3-4097-ad93-456c6132b271",
   "metadata": {},
   "source": [
    "Binary classification models outperform anomaly detection models. This likely stems from the fact that the success of anomaly detection algorithms requires normal data to look significantly different than anomalies, yet in the real world, cancerous and non-cancerous lesions can often appear identical with very similar features. Doctors frequently attest to this trait of skin lesions, as many admit that some of the lesions they believed to be non-cancerous based off appearance were actually cancerous. Unlike anomaly detection algorithms, many binary classification models do not require there to be stark differences in the appearance of lesions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
