{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d35a47-136e-4b7d-a417-28466d595386",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To do:\n",
    "next: add image features from CNN into autoencoder and isolation forest\n",
    "1) figure out how to feature engineer with images (rotations, crops, etc.)\n",
    "2) load images and metadata into autoencoder and get predictions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a54bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import tensorflow as tf\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed058f-8682-4c61-815c-1bcb643be5a4",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cfd6d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions to load, process, and feature extract the images\n",
    "def extract_features(img_batch):\n",
    "    \"\"\"\n",
    "    Extracts features from a batch of images using ResNet50\n",
    "    \n",
    "    :param img_batch: batch of images as numpy arrays\n",
    "    :return: feature vectors for the batch\n",
    "    \"\"\"\n",
    "    # Preprocess batch images to align with ResNet50 requirements\n",
    "    img_batch = np.array([preprocess_input(img) for img in img_batch])\n",
    "    \n",
    "    # Extract features for the entire batch\n",
    "    features = resnet_model.predict(img_batch, verbose=0)\n",
    "    \n",
    "    # Flatten and return the features\n",
    "    return features.reshape(features.shape[0], -1)\n",
    "\n",
    "def load_image(zip_fold, file, img_size):\n",
    "    \"\"\"\n",
    "    Loads and resizes an image from a zip folder\n",
    "    \n",
    "    :param zip_fold: zipped folder object\n",
    "    :param file: filename for image in zip folder\n",
    "    :param img_size: target size for resizing\n",
    "    :return: image as a numpy array\n",
    "    \"\"\"\n",
    "    with zip_fold.open(file) as img_file:\n",
    "        img = load_img(BytesIO(img_file.read()), target_size=img_size)\n",
    "        return img_to_array(img)\n",
    "\n",
    "def get_batch_features(files, z, img_size=(224, 224), batch_size=32, num_workers=4):\n",
    "    \"\"\"\n",
    "    Loads images and extracts feautres with batch processing and a ResNet50 model\n",
    "    \n",
    "    :param files: list of filenames for images\n",
    "    :param z: zipped folder object\n",
    "    :param img_size: target size to resize images\n",
    "    :param batch_size: number of images per batch\n",
    "    :param num_workers: number of threads for parallel processing\n",
    "    :return: feature vectors for images in batches\n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    # Process images in batches\n",
    "    for i in range(0, len(files), batch_size):\n",
    "        batch_files = files[i:i + batch_size]\n",
    "\n",
    "        # Load and preprocess images in parallel\n",
    "        with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "            img_batch = list(executor.map(lambda file: load_image(z, file, img_size), batch_files))\n",
    "\n",
    "        # Extract features for the batch\n",
    "        img_batch = np.array(img_batch)\n",
    "        features = extract_features(img_batch)\n",
    "            \n",
    "        yield features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ce8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the metadata\n",
    "zip_folder = zipfile.ZipFile('anon-patient-data.zip')\n",
    "skin_cancer_df = pd.read_csv(zip_folder.open('train-metadata.csv'), low_memory=False, \n",
    "                            usecols=[num for num in range(0, 43) if num not in [2, 7]], index_col='isic_id')\n",
    "\n",
    "\"\"\"\n",
    "# Load the pre-trained ResNet50 model\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Obtain all JPG image filenames and initialize array for image features\n",
    "img_files = [file for file in zip_folder.namelist() if file.startswith('image/') and file.endswith('.jpg')]\n",
    "images_features = np.zeros((len(img_files), 2048))\n",
    "\n",
    "# Extract image features using ResNet50 and batch processsing\n",
    "idx = 0\n",
    "for batch_features in get_batch_features(img_files, zip_folder, img_size=(224, 224), batch_size=64, num_workers=4):\n",
    "    batch_length = batch_features.shape[0]\n",
    "    images_features[idx:idx + batch_length] = batch_features\n",
    "    idx += batch_length\n",
    "    \n",
    "# Save image data into CSV to avoid unnecesary repetition of ResNet50 process\n",
    "pd.DataFrame(images_features).to_csv('resnet50_features.csv', index=False, header=False)\n",
    "\"\"\"\n",
    "\n",
    "# Read CSV data containing image features from ResNet50 processing commented out above\n",
    "images_features = np.loadtxt('resnet50_features.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46312b22-d34e-49be-a49a-1df8e140cc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(images_features).to_csv('better_resnet50_features.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded8fa8-355f-438d-9396-1768d954cbc8",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of Metadata by Lesion Type (Cancer vs Non-Cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaf24b9-b4c6-4057-892d-28a4d03030e4",
   "metadata": {},
   "source": [
    "### How balanced is the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd2928-db81-494a-8868-ab14f0cc2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the number of cancerous vs non-cancerous lesions in the data\n",
    "not_cancer = skin_cancer_df[skin_cancer_df['target'] == 0]\n",
    "cancer = skin_cancer_df[skin_cancer_df['target'] == 1]\n",
    "print(f'Out of the {len(skin_cancer_df)} lesions in our dataset, {len(not_cancer)} are not cancerous and {len(cancer)} are cancerous.')\n",
    "\n",
    "# Visualize the results in a pie chart\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie([len(not_cancer), len(cancer)], labels=['Not Cancer', 'Cancer'], autopct='%1.1f%%')\n",
    "ax.set_title('Proportion of Cancerous vs Non-Cancerous Lesions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98afe0bc-a75e-488f-992f-1fb90cd1cb6f",
   "metadata": {},
   "source": [
    "#### The data is heavily imbalanced, with almost all available lesions being non-cancerous. This characteristic of the data is our primary motivator for utilizing anomaly detection rather than binary classification as our method for cancer detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6135be-ced6-4818-8c92-ff25335dd8e6",
   "metadata": {},
   "source": [
    "### Do men and women make up different proportions of cancerous vs non-cancerous lesions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759724c1-203b-443c-b12f-f24dc9e97e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the frequencies of each sex for cancerous and non-cancerous lesions\n",
    "gender_freqs_cancer = Counter(cancer['sex'])\n",
    "gender_freqs_noncancer = Counter(not_cancer['sex'])\n",
    "\n",
    "# Visualize the frequencies\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].pie([gender_freqs_noncancer['male'], gender_freqs_noncancer['female'], gender_freqs_noncancer[np.nan]],\n",
    "       labels=['male', 'female', 'NA'], autopct='%1.1f%%')\n",
    "ax[0].set_title('Non-Cancerous Patients')\n",
    "ax[1].pie([gender_freqs_cancer['male'], gender_freqs_cancer['female'], gender_freqs_cancer[np.nan]],\n",
    "       labels=['male', 'female', 'NA'], autopct='%1.1f%%')\n",
    "ax[1].set_title('Cancerous Patients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36365eb6-8c83-42a8-867f-688ea24bce43",
   "metadata": {},
   "source": [
    "#### Men are more represented in cancerous lesions than non-cancerous lesions, which aligns with the notion that men are more likely to obtain skin cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9d5c89-7c82-4499-b262-c3f050b808a0",
   "metadata": {},
   "source": [
    "### Is there a significant difference in the age distribution for cancerous vs non-cancerous patients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578bb0cc-efaa-447e-9e8b-fd6da0a3a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the age distributions\n",
    "plt.hist(cancer['age_approx'], histtype='step', color='red', density=True, label='Cancerous')\n",
    "plt.hist(not_cancer['age_approx'], histtype='step', color='green', density=True, label='Non-Cancerous')\n",
    "plt.legend()\n",
    "plt.xlabel('Age Approximations')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Age Distribution of Cancerous vs Non-Cancerous Patients')\n",
    "plt.show()\n",
    "\n",
    "# Perform the Mann-Whitney U test\n",
    "u_stat, p_value = stats.mannwhitneyu(cancer['age_approx'], not_cancer['age_approx'])\n",
    "\n",
    "# Print the result\n",
    "print(f'Mann-Whitney U test: U-stat = {u_stat}, p-value = {p_value}')\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print('There is a significant difference in the age distribution between cancerous and non-cancerous patients.')\n",
    "else:\n",
    "    print('There is no significant difference in the age distribution between cancerous and non-cancerous patients.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312f25af-0b8b-46ad-8ef3-308ca6249774",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c1bd2-729e-4ff3-bbf7-1792952575a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to compare summary stats for (choose columns that align with the ABCD factors used for skin cancer detection)\n",
    "use_cols = ['tbp_lv_symm_2axis', 'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean', 'clin_size_long_diam_mm']\n",
    "\n",
    "# Present summary statistics for cancerous patients\n",
    "cancer[use_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dfd094-e95c-4bd2-bec5-fb26588fd57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Present summary statistics for non-cancerous patients\n",
    "not_cancer[use_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d6cb8-bd14-4daa-ad13-380d15ec245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Mann-Whitney U test to determine if any of these differences are significant\n",
    "for col in use_cols:\n",
    "    u_stat, p_value = stats.mannwhitneyu(cancer[col], not_cancer[col])\n",
    "    if p_value < 0.05:\n",
    "        print(f'There is a significant difference in {col} between cancerous and non-cancerous patients.')\n",
    "    else:\n",
    "        print(f'There is no significant difference in {col} between cancerous and non-cancerous patients.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65023dfd-22e5-481f-bbb1-31bbd0f6c0e2",
   "metadata": {},
   "source": [
    "### Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bdff5d-9df6-4fae-b02d-ac13d4c99725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with null values for non-cancerous patients\n",
    "not_cancer_nulls = filter(lambda item: item[1] > 0, not_cancer.isnull().sum().items())\n",
    "print('Columns with null values for non-cancerous patients:')\n",
    "for tup in not_cancer_nulls:\n",
    "    print(f'Column: {tup[0]}, No. of Nulls: {tup[1]}, As a %: {round(tup[1]/len(cancer[tup[0]]), 2)}')\n",
    "    \n",
    "# Identify columns with null values for cancerous patients\n",
    "cancer_nulls = filter(lambda item: item[1] > 0, cancer.isnull().sum().items())\n",
    "print('\\nColumns with null values for cancerous patients:')\n",
    "for tup in cancer_nulls:\n",
    "    print(f'Column: {tup[0]}, No. of Nulls: {tup[1]}, As a %: {round(tup[1]/len(cancer[tup[0]]), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c3c95",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the categorical (nominal) features\n",
    "categorical_features = skin_cancer_df.select_dtypes(include=['object', 'category', 'string']).columns.tolist()\n",
    "\n",
    "# Impute and encode values in categorical columns\n",
    "updated_features = []\n",
    "for feature in categorical_features:\n",
    "    \n",
    "    # Impute null values in categorical features with the mode\n",
    "    skin_cancer_df[feature] = skin_cancer_df[feature].fillna(skin_cancer_df[feature].mode()[0])\n",
    "    \n",
    "    # Apply one-hot encoding to categorical (nominal) variables\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoded_feature = encoder.fit_transform(skin_cancer_df[[feature]])\n",
    "    \n",
    "    # Add the encoded columns to the dataframe\n",
    "    encoded_col_names = [f\"{feature}_{cat}\" for cat in encoder.categories_[0]]\n",
    "    encoded_feature_df = pd.DataFrame(encoded_feature, columns=encoded_col_names, index=skin_cancer_df.index)\n",
    "    skin_cancer_df = pd.concat([skin_cancer_df, encoded_feature_df], axis=1)\n",
    "    updated_features += encoded_col_names\n",
    "    \n",
    "# Remove unencoded categorical columns\n",
    "skin_cancer_df = skin_cancer_df.drop(columns=categorical_features)\n",
    "updated_cols = skin_cancer_df.columns\n",
    " \n",
    "# Use KNN to impute null values in the numerical columns\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputed_array = imputer.fit_transform(skin_cancer_df)\n",
    "skin_cancer_df = pd.DataFrame(imputed_array, columns=updated_cols, index=skin_cancer_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cd266b",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4951a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing which features to use from feature engineering\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Creates new features to help the model evaluate the ABCD factors used by dermatologists\n",
    "    :param df: a dataframe to add new features to\n",
    "    :return: the input dataframe with updated features\n",
    "    \"\"\"\n",
    "    og_cols = len(df.columns)\n",
    "    # A - Asymmetry, Border irregularity/bluriness, and Diameter (skin cancer diameter usually > 6 mm)\n",
    "    df['diameter_ratio'] = df['tbp_lv_minorAxisMM'] / df['clin_size_long_diam_mm']\n",
    "    df['area_irregularity'] = np.abs((np.pi * (df['clin_size_long_diam_mm'] / 2)**2) - (df['tbp_lv_areaMM2'])**(1/2))\n",
    "    df['perimeter_irregularity'] = np.abs((np.pi * df['clin_size_long_diam_mm']) - df['tbp_lv_perimeterMM'])\n",
    "    df['area_perimeter_ratio'] = df['tbp_lv_areaMM2'] / (df['tbp_lv_perimeterMM'] ** 2)\n",
    "    df['large_diameter'] = [1 if val > 5.5 else 0 for val in df['clin_size_long_diam_mm']] # skin cancer diameters tend to be larger than 6 mm\n",
    "    df['perimeter_to_area'] = (df['tbp_lv_perimeterMM']**2) / df['tbp_lv_areaMM2']\n",
    "    df['avg_normalized_irregularity'] = (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"]) / 2\n",
    "    \n",
    "    # Color (variation)  \n",
    "    df['hc_mean_contrast'] = ((df['tbp_lv_H'] + df['tbp_lv_Hext']) / 2) + ((df['tbp_lv_C'] + df['tbp_lv_Cext']) / 2)\n",
    "    df['tbp_lv_deltaH'] = np.abs(df['tbp_lv_H'] - df['tbp_lv_Hext'])\n",
    "    df['tbp_lv_deltaC'] = np.abs(df['tbp_lv_C'] + df['tbp_lv_Cext'])\n",
    "    df['overall_lab_contrast'] = np.sqrt(df['tbp_lv_deltaL']**2 + df['tbp_lv_deltaA']**2 + df['tbp_lv_deltaB']**2)\n",
    "    df['large_color_variance'] = [1 if val > 4 else 0 for val in df['tbp_lv_color_std_mean']]\n",
    "    df['average_lab_contrast'] = (df['tbp_lv_deltaL'] + df['tbp_lv_deltaA'] + df['tbp_lv_deltaB']) / 3\n",
    "    \n",
    "    # Features to maximize other features\n",
    "    df['lesion_location'] = np.sqrt(df['tbp_lv_x']**2 + df['tbp_lv_y']**2 + df['tbp_lv_z']**2) # l2 norm of lesion coordinates\n",
    "    print(f'Created {len(df.columns) - og_cols} New Features During Feature Engineering')\n",
    "    df = df.drop(['tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z'], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "skin_cancer_enhanced = create_features(skin_cancer_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda0a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe use these features in feature engineering\n",
    "\n",
    "def create_new_features(df):\n",
    "    # Create new features\n",
    "    df[\"color_uniformity\"] = np.where(df[\"tbp_lv_radial_color_std_max\"] == 0, 0, (df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_radial_color_std_max\"]))\n",
    "    df[\"size_age_interaction\"] = df[\"clin_size_long_diam_mm\"] * df[\"age_approx\"]\n",
    "    \n",
    "    df[\"log_lesion_area\"] = np.log(df[\"tbp_lv_areaMM2\"] + 1)\n",
    "    df[\"mean_hue_difference\"] = (df[\"tbp_lv_H\"] + df[\"tbp_lv_Hext\"]) / 2\n",
    "\n",
    "    return df\n",
    "\n",
    "skin_cancer_enhanced = create_new_features(skin_cancer_enhanced.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d774b4-e842-464c-b9b1-735187206cd1",
   "metadata": {},
   "source": [
    "# Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5273c102-4575-4bce-abb6-c1461a9e4f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "og_cols = len(skin_cancer_enhanced.columns)\n",
    "corr_matrix = skin_cancer_enhanced.corr().abs()\n",
    "\n",
    "# Remove repetitions by only keeping values in upper, right triangle\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Drop features with correlations to other features greater than 0.8\n",
    "threshold = 0.8\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "skin_cancer_enhanced = skin_cancer_enhanced.drop(to_drop, axis=1)\n",
    "print(f'Removed {og_cols - len(skin_cancer_enhanced.columns)} Features with High Correlation to Another Feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed6fa1-c51e-4498-906c-4a9269950edb",
   "metadata": {},
   "source": [
    "# Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149cde8a-2d87-4d7c-b216-cf5f13727be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importances using ANOVA f-test\n",
    "fs = SelectKBest(score_func=f_classif, k='all')\n",
    "skin_cancer_array = fs.fit_transform(skin_cancer_enhanced.drop(['target', 'image_path'], axis=1), skin_cancer_enhanced['target'])\n",
    "use_cols = skin_cancer_enhanced.drop(['target', 'image_path'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a9403-c75a-4095-b48a-d46d734b2da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar([use_cols[i] for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b69d8e8",
   "metadata": {},
   "source": [
    "# Aggregate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine enhanced metadata and image features into one data set\n",
    "images_features = images_features[1:, :]\n",
    "images_features = pd.DataFrame(images_features)\n",
    "skin_cancer_features = skin_cancer_enhanced.drop('target', axis=1)\n",
    "skin_cancer_full = pd.concat([skin_cancer_features.reset_index(), images_features], axis=1)\n",
    "skin_cancer_full.columns = skin_cancer_full.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8878def9",
   "metadata": {},
   "source": [
    "# Isolation Forest - gives worse results than autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df49a024-12cd-4d3f-8335-1ea068c9e3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d67f2b8f-e450-4b6c-a5bb-a1e8c0f4aff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huebscher.m/.local/lib/python3.8/site-packages/imblearn/over_sampling/_smote/base.py:370: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S.S.: 0.17, Estimators: 60, f1_score: 0.35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.83      0.86    400666\n",
      "         1.0       0.30      0.43      0.35     68113\n",
      "\n",
      "    accuracy                           0.77    468779\n",
      "   macro avg       0.60      0.63      0.61    468779\n",
      "weighted avg       0.81      0.77      0.79    468779\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huebscher.m/.local/lib/python3.8/site-packages/imblearn/over_sampling/_smote/base.py:370: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S.S.: 0.19, Estimators: 60, f1_score: 0.37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.81      0.85    400666\n",
      "         1.0       0.32      0.46      0.37     76126\n",
      "\n",
      "    accuracy                           0.75    476792\n",
      "   macro avg       0.60      0.64      0.61    476792\n",
      "weighted avg       0.80      0.75      0.77    476792\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huebscher.m/.local/lib/python3.8/site-packages/imblearn/over_sampling/_smote/base.py:370: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S.S.: 0.21, Estimators: 60, f1_score: 0.39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.79      0.83    400666\n",
      "         1.0       0.33      0.49      0.39     84139\n",
      "\n",
      "    accuracy                           0.74    484805\n",
      "   macro avg       0.60      0.64      0.61    484805\n",
      "weighted avg       0.78      0.74      0.76    484805\n",
      "\n",
      "Best Hyperparameters + result: (0.21, 60) \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.79      0.83    400666\n",
      "         1.0       0.33      0.49      0.39     84139\n",
      "\n",
      "    accuracy                           0.74    484805\n",
      "   macro avg       0.60      0.64      0.61    484805\n",
      "weighted avg       0.78      0.74      0.76    484805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best = (0, 0, 0, None)\n",
    "for ss in [x*0.01 for x in range(21, 33, 2)]:\n",
    "    # Oversample the minority group to make the data more balanced\n",
    "    smote = SMOTE(sampling_strategy=ss, random_state=42, n_jobs=3)\n",
    "    X_resampled, y_resampled = smote.fit_resample(skin_cancer_full.drop('isic_id', axis=1), skin_cancer_df['target'])\n",
    "\n",
    "    # Split the data - training is non-cancerous, test is on all patients to detect anomalies\n",
    "    X_train = X_resampled[y_resampled == 0]\n",
    "    X_test = X_resampled\n",
    "\n",
    "    # Scale the data between 0 and 1\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Develop and train the Isolation Forest model\n",
    "    c = len(y_resampled[y_resampled == 1]) / len(y_resampled[y_resampled == 0])\n",
    "    for estimators in range(60, 120, 10):\n",
    "        isf = IsolationForest(n_estimators=estimators, contamination=c, random_state=42)\n",
    "        isf.fit(X_train)\n",
    "\n",
    "        # Predict the targets for the test data\n",
    "        preds = isf.predict(X_test)\n",
    "        y_preds = [1 if p == -1 else 0 for p in preds]\n",
    "\n",
    "        # Evaluate the models performance on testing data\n",
    "        cr = classification_report(y_resampled, y_preds)\n",
    "        f1_score = float(cr.split()[12])\n",
    "        if f1_score > best[2]:\n",
    "            best = (ss, estimators, f1_score, cr)\n",
    "            print(f'\\nS.S.: {ss}, Estimators: {estimators}, f1_score: {f1_score}')\n",
    "            print(cr)\n",
    "print('Best Hyperparameters + result:', best[:2], '\\n', best[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46692e4a",
   "metadata": {},
   "source": [
    "# Autoencoder - best when dropout is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abc06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning - training on non-cancerous patients, w feature engineering\n",
    "best = (0, 0, 0, None)\n",
    "# Oversample the minority group to make the data more balanced\n",
    "for ss in range(5, 35, 10):\n",
    "    smote = SMOTE(sampling_strategy=ss*0.01, random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(skin_cancer_full.drop('isic_id', axis=1), skin_cancer_df['target'])\n",
    "\n",
    "    # Split the data - training is non-cancerous, test is on all patients to detect anomalies\n",
    "    X_train = X_resampled[y_resampled == 0]\n",
    "    X_test = X_resampled\n",
    "\n",
    "    # Scale the data between 0 and 1\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Build the autoencoder model - dropout of 5 works best\n",
    "    for d in range(0, 10, 2):\n",
    "        \n",
    "        autoencoder = Sequential([\n",
    "            Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
    "            Dropout(d*0.1),  \n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(d*0.1),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(d*0.1),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(d*0.1),\n",
    "            Dense(X_train.shape[1], activation='sigmoid')  # Output layer should match input\n",
    "        ])\n",
    "\n",
    "        autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "        # Train the autoencoder using only the non-cancerous patients\n",
    "        history = autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, validation_split=0.1,\n",
    "                                 callbacks=[early_stopping])\n",
    "\n",
    "        # Find the epoch with the lowest validation loss\n",
    "        best_epoch = np.argmin(history.history['val_loss']) + 1  # Add 1 since epochs are 1-indexed\n",
    "        best_val_loss = np.min(history.history['val_loss'])\n",
    "\n",
    "        # Calculate reconstruction error for each sample\n",
    "        reconstructed = autoencoder.predict(X_test)\n",
    "        reconstruction_error = np.mean(np.abs(reconstructed - X_test), axis=1)\n",
    "\n",
    "        # Threshold the reconstruction error to detect anomalies\n",
    "        for thresh in range(97, 100):\n",
    "            threshold = np.percentile(reconstruction_error, thresh)  # Set threshold (e.g., 99th percentile)\n",
    "            predictions_autoencoder = (reconstruction_error > threshold).astype(int)  # 1 = anomaly (cancer), 0 = normal\n",
    "            cr = classification_report(y_resampled, predictions_autoencoder)\n",
    "            f1_score = float(cr.split()[12])\n",
    "            print(f'\\nS.S.: {ss*.01}, Dropout: {d*.1}, Threshold: {thresh}, Best Epoch {best_epoch}',\n",
    "                  f'f1 score: {f1_score}\\n', cr)\n",
    "            if f1_score > best[2]:\n",
    "                best = (ss, d, thresh, best_epoch, f1_score, cr)\n",
    "\n",
    "print('Best:')\n",
    "print(best[:4])\n",
    "print(best[5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
