{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff7880fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf0578",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'male'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e2234b1510a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Fill in blank values in columns using a KNN imputer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mimputer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNNImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mskin_cancer_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'age_approx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskin_cancer_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'age_approx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    917\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1150\u001b[0m                 )\n\u001b[0;32m   1151\u001b[0m             ):\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_knn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    230\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2064\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2066\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'male'"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "zip_folder = zipfile.ZipFile('anon-patient-data.zip')\n",
    "skin_cancer_df = pd.read_csv(zip_folder.open('train-metadata.csv'), \n",
    "                             usecols=[num for num in range(0, 43) if num not in [2, 7]], index_col='isic_id')\n",
    "\n",
    "# Convert categorical data to numbers\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "for feature in ['sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple', 'tbp_tile_type']:\n",
    "    skin_cancer_df[feature] = encoder.fit_transform(skin_cancer_df[feature])\n",
    "\n",
    "# Fill in blank values in columns using a KNN imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "skin_cancer_df[['age_approx', 'sex']] = imputer.fit_transform(skin_cancer_df[['age_approx', 'sex']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797adbb2",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d0a3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "zip_folder = zipfile.ZipFile('anon-patient-data.zip')\n",
    "skin_cancer_df = pd.read_csv(zip_folder.open('train-metadata.csv'), \n",
    "                             usecols=[num for num in range(0, 43) if num not in [2, 7]], index_col='isic_id')\n",
    "\n",
    "# Convert categorical data to numbers\n",
    "encoder = LabelEncoder()\n",
    "for feature in ['sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple', 'tbp_tile_type']:\n",
    "    skin_cancer_df[feature] = encoder.fit_transform(skin_cancer_df[feature])\n",
    "\n",
    "# Fill in blank values in columns using a KNN imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "skin_cancer_df[['age_approx', 'sex']] = imputer.fit_transform(skin_cancer_df[['age_approx', 'sex']])\n",
    "\n",
    "# Oversample the minority group to make the data more balanced\n",
    "smote = SMOTE(sampling_strategy=0.21, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(skin_cancer_df.iloc[:, 1:], skin_cancer_df.iloc[:, 0])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(X_resampled, y_resampled, stratify=y_resampled, random_state=42)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_rest, y_rest, stratify=y_rest, random_state=42)\n",
    "\n",
    "# Scale the data between 0 and 1\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_validation = scaler.transform(X_validation)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdea2e3",
   "metadata": {},
   "source": [
    "# Method 1: Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e48252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba2e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=0.21, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(skin_cancer_df.iloc[:, 1:], skin_cancer_df.iloc[:, 0])\n",
    "\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(X_resampled, y_resampled, stratify=y_resampled, random_state=42)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_rest, y_rest, stratify=y_rest, random_state=42)\n",
    "\n",
    "X_train = X_train[y_train == 0]\n",
    "\n",
    "# Scale the data between 0 and 1\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_validation = scaler.transform(X_validation)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Develop and train the Isolation Forest model\n",
    "c = len([1 for target in y_train if target == 1]) / len(y_train)\n",
    "\n",
    "isf = IsolationForest(n_estimators=50, contamination=c, random_state=42)\n",
    "isf.fit(X_train)\n",
    "\n",
    "# Predict the targets for the validation data\n",
    "isf_validation_preds = isf.predict(X_validation)\n",
    "isf_valid_pred = [1 if p == -1 else 0 for p in isf_validation_preds]\n",
    "\n",
    "cr = classification_report(y_validation, isf_valid_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=0.21, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(skin_cancer_df.iloc[:, 1:], skin_cancer_df.iloc[:, 0])\n",
    "\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(X_resampled, y_resampled, stratify=y_resampled, random_state=42)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_rest, y_rest, stratify=y_rest, random_state=42)\n",
    "\n",
    "# Scale the data between 0 and 1\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_validation = scaler.transform(X_validation)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Develop and train the Isolation Forest model\n",
    "c = len([1 for target in y_train if target == 1]) / len(y_train)\n",
    "\n",
    "isf = IsolationForest(n_estimators=50, contamination=c, random_state=42)\n",
    "isf.fit(X_train)\n",
    "\n",
    "# Predict the targets for the validation data\n",
    "isf_validation_preds = isf.predict(X_validation)\n",
    "isf_valid_pred = [1 if p == -1 else 0 for p in isf_validation_preds]\n",
    "\n",
    "cr = classification_report(y_validation, isf_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee6034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "best = (0, 0, 0, None)\n",
    "for ss in [x*0.01 for x in range(3, 19, 2)]:\n",
    "    # Oversample the minority group to make the data more balanced\n",
    "    smote = SMOTE(sampling_strategy=ss, random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(skin_cancer_df.iloc[:, 1:], skin_cancer_df.iloc[:, 0])\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_rest, y_train, y_rest = train_test_split(X_resampled, y_resampled, stratify=y_resampled, random_state=42)\n",
    "    X_validation, X_test, y_validation, y_test = train_test_split(X_rest, y_rest, stratify=y_rest, random_state=42)\n",
    "\n",
    "    # Scale the data between 0 and 1\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_validation = scaler.transform(X_validation)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Develop and train the Isolation Forest model\n",
    "    c = len([1 for target in y_train if target == 1]) / len(y_train)\n",
    "    for estimators in range(50, 120, 10):\n",
    "        isf = IsolationForest(n_estimators=estimators, contamination=c, random_state=42)\n",
    "        isf.fit(X_train)\n",
    "\n",
    "        # Predict the targets for the validation data\n",
    "        isf_validation_preds = isf.predict(X_validation)\n",
    "        isf_valid_pred = [1 if p == -1 else 0 for p in isf_validation_preds]\n",
    "\n",
    "        # Evaluate the models performance on validation data\n",
    "        #print(f'\\nS.S.: {ss}, Estimators: {estimators}')\n",
    "        cr = classification_report(y_validation, isf_valid_pred)\n",
    "        f1_score = float(cr.split()[12])\n",
    "        if f1_score > best[2]:\n",
    "            best = (ss, estimators, f1_score, cr)\n",
    "        print(f'\\nS.S.: {ss}, Estimators: {estimators}, f1_score: {f1_score}')\n",
    "        print(cr)\n",
    "print('Best Hyperparameters + result:', best[:2], '\\n', best[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5c9898b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S.S.: 0.17, Estimators: 50, f1_score: 0.43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88    400666\n",
      "           1       0.37      0.51      0.43     68113\n",
      "\n",
      "    accuracy                           0.80    468779\n",
      "   macro avg       0.64      0.68      0.66    468779\n",
      "weighted avg       0.83      0.80      0.82    468779\n",
      "\n",
      "\n",
      "S.S.: 0.17, Estimators: 60, f1_score: 0.43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88    400666\n",
      "           1       0.37      0.50      0.43     68113\n",
      "\n",
      "    accuracy                           0.80    468779\n",
      "   macro avg       0.64      0.68      0.65    468779\n",
      "weighted avg       0.83      0.80      0.82    468779\n",
      "\n",
      "\n",
      "S.S.: 0.17, Estimators: 70, f1_score: 0.43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88    400666\n",
      "           1       0.37      0.51      0.43     68113\n",
      "\n",
      "    accuracy                           0.80    468779\n",
      "   macro avg       0.64      0.68      0.66    468779\n",
      "weighted avg       0.83      0.80      0.82    468779\n",
      "\n",
      "\n",
      "S.S.: 0.17, Estimators: 80, f1_score: 0.43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88    400666\n",
      "           1       0.38      0.51      0.43     68113\n",
      "\n",
      "    accuracy                           0.81    468779\n",
      "   macro avg       0.64      0.68      0.66    468779\n",
      "weighted avg       0.83      0.81      0.82    468779\n",
      "\n",
      "\n",
      "S.S.: 0.17, Estimators: 90, f1_score: 0.42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88    400666\n",
      "           1       0.37      0.50      0.42     68113\n",
      "\n",
      "    accuracy                           0.80    468779\n",
      "   macro avg       0.64      0.68      0.65    468779\n",
      "weighted avg       0.83      0.80      0.81    468779\n",
      "\n",
      "\n",
      "S.S.: 0.17, Estimators: 100, f1_score: 0.42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88    400666\n",
      "           1       0.37      0.50      0.42     68113\n",
      "\n",
      "    accuracy                           0.80    468779\n",
      "   macro avg       0.64      0.68      0.65    468779\n",
      "weighted avg       0.83      0.80      0.81    468779\n",
      "\n",
      "\n",
      "S.S.: 0.17, Estimators: 110, f1_score: 0.43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88    400666\n",
      "           1       0.37      0.50      0.43     68113\n",
      "\n",
      "    accuracy                           0.80    468779\n",
      "   macro avg       0.64      0.68      0.65    468779\n",
      "weighted avg       0.83      0.80      0.82    468779\n",
      "\n",
      "\n",
      "S.S.: 0.19, Estimators: 50, f1_score: 0.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87    400666\n",
      "           1       0.39      0.53      0.45     76126\n",
      "\n",
      "    accuracy                           0.79    476792\n",
      "   macro avg       0.65      0.69      0.66    476792\n",
      "weighted avg       0.82      0.79      0.80    476792\n",
      "\n",
      "\n",
      "S.S.: 0.19, Estimators: 60, f1_score: 0.44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87    400666\n",
      "           1       0.38      0.52      0.44     76126\n",
      "\n",
      "    accuracy                           0.79    476792\n",
      "   macro avg       0.64      0.68      0.66    476792\n",
      "weighted avg       0.82      0.79      0.80    476792\n",
      "\n",
      "\n",
      "S.S.: 0.19, Estimators: 70, f1_score: 0.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87    400666\n",
      "           1       0.39      0.53      0.45     76126\n",
      "\n",
      "    accuracy                           0.79    476792\n",
      "   macro avg       0.64      0.68      0.66    476792\n",
      "weighted avg       0.82      0.79      0.80    476792\n",
      "\n",
      "\n",
      "S.S.: 0.19, Estimators: 80, f1_score: 0.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87    400666\n",
      "           1       0.39      0.53      0.45     76126\n",
      "\n",
      "    accuracy                           0.79    476792\n",
      "   macro avg       0.65      0.69      0.66    476792\n",
      "weighted avg       0.82      0.79      0.80    476792\n",
      "\n",
      "\n",
      "S.S.: 0.19, Estimators: 90, f1_score: 0.44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87    400666\n",
      "           1       0.38      0.52      0.44     76126\n",
      "\n",
      "    accuracy                           0.79    476792\n",
      "   macro avg       0.64      0.68      0.66    476792\n",
      "weighted avg       0.82      0.79      0.80    476792\n",
      "\n",
      "\n",
      "S.S.: 0.19, Estimators: 100, f1_score: 0.44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87    400666\n",
      "           1       0.38      0.52      0.44     76126\n",
      "\n",
      "    accuracy                           0.79    476792\n",
      "   macro avg       0.64      0.68      0.66    476792\n",
      "weighted avg       0.82      0.79      0.80    476792\n",
      "\n",
      "\n",
      "S.S.: 0.19, Estimators: 110, f1_score: 0.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87    400666\n",
      "           1       0.39      0.53      0.45     76126\n",
      "\n",
      "    accuracy                           0.79    476792\n",
      "   macro avg       0.64      0.68      0.66    476792\n",
      "weighted avg       0.82      0.79      0.80    476792\n",
      "\n",
      "\n",
      "S.S.: 0.21, Estimators: 50, f1_score: 0.47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86    400666\n",
      "           1       0.40      0.55      0.47     84139\n",
      "\n",
      "    accuracy                           0.78    484805\n",
      "   macro avg       0.65      0.69      0.66    484805\n",
      "weighted avg       0.81      0.78      0.79    484805\n",
      "\n",
      "\n",
      "S.S.: 0.21, Estimators: 60, f1_score: 0.46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86    400666\n",
      "           1       0.40      0.55      0.46     84139\n",
      "\n",
      "    accuracy                           0.78    484805\n",
      "   macro avg       0.65      0.69      0.66    484805\n",
      "weighted avg       0.81      0.78      0.79    484805\n",
      "\n",
      "\n",
      "S.S.: 0.21, Estimators: 70, f1_score: 0.46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86    400666\n",
      "           1       0.40      0.55      0.46     84139\n",
      "\n",
      "    accuracy                           0.78    484805\n",
      "   macro avg       0.65      0.69      0.66    484805\n",
      "weighted avg       0.81      0.78      0.79    484805\n",
      "\n",
      "\n",
      "S.S.: 0.21, Estimators: 80, f1_score: 0.47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86    400666\n",
      "           1       0.40      0.56      0.47     84139\n",
      "\n",
      "    accuracy                           0.78    484805\n",
      "   macro avg       0.65      0.69      0.66    484805\n",
      "weighted avg       0.81      0.78      0.79    484805\n",
      "\n",
      "\n",
      "S.S.: 0.21, Estimators: 90, f1_score: 0.46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86    400666\n",
      "           1       0.40      0.55      0.46     84139\n",
      "\n",
      "    accuracy                           0.78    484805\n",
      "   macro avg       0.65      0.69      0.66    484805\n",
      "weighted avg       0.81      0.78      0.79    484805\n",
      "\n",
      "\n",
      "S.S.: 0.21, Estimators: 100, f1_score: 0.46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86    400666\n",
      "           1       0.40      0.55      0.46     84139\n",
      "\n",
      "    accuracy                           0.78    484805\n",
      "   macro avg       0.65      0.69      0.66    484805\n",
      "weighted avg       0.81      0.78      0.79    484805\n",
      "\n",
      "\n",
      "S.S.: 0.21, Estimators: 110, f1_score: 0.46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86    400666\n",
      "           1       0.40      0.55      0.46     84139\n",
      "\n",
      "    accuracy                           0.78    484805\n",
      "   macro avg       0.65      0.69      0.66    484805\n",
      "weighted avg       0.81      0.78      0.79    484805\n",
      "\n",
      "Best Hyperparameters + result: (0.21, 50) \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86    400666\n",
      "           1       0.40      0.55      0.47     84139\n",
      "\n",
      "    accuracy                           0.78    484805\n",
      "   macro avg       0.65      0.69      0.66    484805\n",
      "weighted avg       0.81      0.78      0.79    484805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Other way to train the isolation forest - only train on the non-cancerous patients\n",
    "\n",
    "# Hyperparameter tuning\n",
    "best = (0, 0, 0, None)\n",
    "for ss in [x*0.01 for x in range(17, 23, 2)]:\n",
    "    # Oversample the minority group to make the data more balanced\n",
    "    smote = SMOTE(sampling_strategy=ss, random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(skin_cancer_df.iloc[:, 1:], skin_cancer_df.iloc[:, 0])\n",
    "\n",
    "    # Split the data - training is non-cancerous, test is on all patients to detect anomalies\n",
    "    X_train = X_resampled[y_resampled == 0]\n",
    "    X_test = X_resampled\n",
    "\n",
    "    # Scale the data between 0 and 1\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Develop and train the Isolation Forest model\n",
    "    c = len(y_resampled[y_resampled == 1]) / len(y_resampled)\n",
    "    for estimators in range(50, 120, 10):\n",
    "        isf = IsolationForest(n_estimators=estimators, contamination=c, random_state=42)\n",
    "        isf.fit(X_train)\n",
    "\n",
    "        # Predict the targets for the test data\n",
    "        preds = isf.predict(X_test)\n",
    "        y_preds = [1 if p == -1 else 0 for p in preds]\n",
    "\n",
    "        # Evaluate the models performance on testing data\n",
    "        cr = classification_report(y_resampled, y_preds)\n",
    "        f1_score = float(cr.split()[12])\n",
    "        if f1_score > best[2]:\n",
    "            best = (ss, estimators, f1_score, cr)\n",
    "        print(f'\\nS.S.: {ss}, Estimators: {estimators}, f1_score: {f1_score}')\n",
    "        print(cr)\n",
    "print('Best Hyperparameters + result:', best[:2], '\\n', best[3])\n",
    "\n",
    "# Make predictions for the entire data set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96941ac8",
   "metadata": {},
   "source": [
    "# Method 3: Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c019205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11269/11269 [==============================] - 27s 2ms/step - loss: 0.0012 - val_loss: 2.4185e-04\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 2.0556e-04 - val_loss: 1.6158e-04\n",
      "Epoch 3/100\n",
      "11269/11269 [==============================] - 18s 2ms/step - loss: 1.7527e-04 - val_loss: 1.4138e-04\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 18s 2ms/step - loss: 1.4111e-04 - val_loss: 1.2920e-04\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 1.3950e-04 - val_loss: 1.3579e-04\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 33s 3ms/step - loss: 2.0343e-04 - val_loss: 1.5278e-04\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 28s 2ms/step - loss: 1.2844e-04 - val_loss: 1.3553e-04\n",
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 30s 3ms/step - loss: 0.0034 - val_loss: 0.0075\n",
      "Epoch 9/100\n",
      "11269/11269 [==============================] - 17s 1ms/step - loss: 0.0035 - val_loss: 1.0272e-04\n",
      "Epoch 10/100\n",
      "11269/11269 [==============================] - 17s 2ms/step - loss: 1.0522e-04 - val_loss: 1.0078e-04\n",
      "Epoch 11/100\n",
      "11269/11269 [==============================] - 17s 1ms/step - loss: 1.1785e-04 - val_loss: 1.1450e-04\n",
      "Epoch 12/100\n",
      "11269/11269 [==============================] - 19s 2ms/step - loss: 1.0956e-04 - val_loss: 9.9983e-05\n",
      "Epoch 13/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 1.5550e-04 - val_loss: 7.7146e-05\n",
      "Epoch 14/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0016 - val_loss: 9.2303e-05\n",
      "Epoch 15/100\n",
      "11269/11269 [==============================] - 19s 2ms/step - loss: 9.9927e-05 - val_loss: 1.1418e-04\n",
      "Epoch 16/100\n",
      "11269/11269 [==============================] - 18s 2ms/step - loss: 9.2243e-05 - val_loss: 9.0116e-05\n",
      "Epoch 17/100\n",
      "11269/11269 [==============================] - 19s 2ms/step - loss: 9.3106e-05 - val_loss: 8.5258e-05\n",
      "Epoch 18/100\n",
      "11269/11269 [==============================] - 17s 1ms/step - loss: 9.2447e-05 - val_loss: 9.3113e-05\n",
      "Epoch 19/100\n",
      "11269/11269 [==============================] - 18s 2ms/step - loss: 8.7543e-05 - val_loss: 8.0323e-05\n",
      "Epoch 20/100\n",
      "11269/11269 [==============================] - 19s 2ms/step - loss: 0.0024 - val_loss: 0.0075\n",
      "Epoch 21/100\n",
      "11269/11269 [==============================] - 17s 1ms/step - loss: 0.0070 - val_loss: 1.1547e-04\n",
      "Epoch 22/100\n",
      "11269/11269 [==============================] - 16s 1ms/step - loss: 1.0592e-04 - val_loss: 9.2442e-05\n",
      "Epoch 23/100\n",
      "11269/11269 [==============================] - 16s 1ms/step - loss: 9.2426e-05 - val_loss: 9.5679e-05\n",
      "13147/13147 [==============================] - 11s 837us/step\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.0, Threshold: 97, Best Epoch 13 f1 score: 0.37\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97    400666\n",
      "           1       0.48      0.30      0.37     20033\n",
      "\n",
      "    accuracy                           0.95    420699\n",
      "   macro avg       0.72      0.64      0.67    420699\n",
      "weighted avg       0.94      0.95      0.95    420699\n",
      "\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.0, Threshold: 98, Best Epoch 13 f1 score: 0.32\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98    400666\n",
      "           1       0.54      0.23      0.32     20033\n",
      "\n",
      "    accuracy                           0.95    420699\n",
      "   macro avg       0.75      0.61      0.65    420699\n",
      "weighted avg       0.94      0.95      0.94    420699\n",
      "\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.0, Threshold: 99, Best Epoch 13 f1 score: 0.21\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    400666\n",
      "           1       0.61      0.13      0.21     20033\n",
      "\n",
      "    accuracy                           0.95    420699\n",
      "   macro avg       0.78      0.56      0.59    420699\n",
      "weighted avg       0.94      0.95      0.94    420699\n",
      "\n",
      "Epoch 1/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0070 - val_loss: 0.0032\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 3/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 9/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 10/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 11/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 12/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 13/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 14/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 15/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 16/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 17/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 18/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 19/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 20/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 21/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 22/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "13147/13147 [==============================] - 11s 813us/step\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.2, Threshold: 97, Best Epoch 12 f1 score: 0.25\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97    400666\n",
      "           1       0.33      0.21      0.25     20033\n",
      "\n",
      "    accuracy                           0.94    420699\n",
      "   macro avg       0.64      0.59      0.61    420699\n",
      "weighted avg       0.93      0.94      0.94    420699\n",
      "\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.2, Threshold: 98, Best Epoch 12 f1 score: 0.21\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97    400666\n",
      "           1       0.36      0.15      0.21     20033\n",
      "\n",
      "    accuracy                           0.95    420699\n",
      "   macro avg       0.66      0.57      0.59    420699\n",
      "weighted avg       0.93      0.95      0.94    420699\n",
      "\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.2, Threshold: 99, Best Epoch 12 f1 score: 0.13\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97    400666\n",
      "           1       0.39      0.08      0.13     20033\n",
      "\n",
      "    accuracy                           0.95    420699\n",
      "   macro avg       0.67      0.54      0.55    420699\n",
      "weighted avg       0.93      0.95      0.93    420699\n",
      "\n",
      "Epoch 1/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0116 - val_loss: 0.0067\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 3/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 0.0079 - val_loss: 0.0056\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0077 - val_loss: 0.0056\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0074 - val_loss: 0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 0.0073 - val_loss: 0.0052\n",
      "Epoch 9/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 10/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 11/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 12/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 13/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 14/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 15/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 16/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 17/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 18/100\n",
      "11269/11269 [==============================] - 27s 2ms/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 19/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 20/100\n",
      "11269/11269 [==============================] - 35s 3ms/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 21/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0072 - val_loss: 0.0051\n",
      "13147/13147 [==============================] - 11s 861us/step\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.4, Threshold: 97, Best Epoch 11 f1 score: 0.12\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96    400666\n",
      "           1       0.15      0.10      0.12     20033\n",
      "\n",
      "    accuracy                           0.93    420699\n",
      "   macro avg       0.55      0.53      0.54    420699\n",
      "weighted avg       0.92      0.93      0.92    420699\n",
      "\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.4, Threshold: 98, Best Epoch 11 f1 score: 0.09\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97    400666\n",
      "           1       0.15      0.06      0.09     20033\n",
      "\n",
      "    accuracy                           0.94    420699\n",
      "   macro avg       0.55      0.52      0.53    420699\n",
      "weighted avg       0.92      0.94      0.93    420699\n",
      "\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.4, Threshold: 99, Best Epoch 11 f1 score: 0.06\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    400666\n",
      "           1       0.17      0.04      0.06     20033\n",
      "\n",
      "    accuracy                           0.95    420699\n",
      "   macro avg       0.56      0.51      0.52    420699\n",
      "weighted avg       0.92      0.95      0.93    420699\n",
      "\n",
      "Epoch 1/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0166 - val_loss: 0.0123\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 3/100\n",
      "11269/11269 [==============================] - 31s 3ms/step - loss: 0.0135 - val_loss: 0.0121\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 27s 2ms/step - loss: 0.0133 - val_loss: 0.0118\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 27s 2ms/step - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 9/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0128 - val_loss: 0.0110\n",
      "Epoch 10/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0129 - val_loss: 0.0110\n",
      "Epoch 11/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0128 - val_loss: 0.0108\n",
      "Epoch 12/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0128 - val_loss: 0.0110\n",
      "Epoch 13/100\n",
      "11269/11269 [==============================] - 27s 2ms/step - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 14/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0128 - val_loss: 0.0110\n",
      "Epoch 15/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 16/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0128 - val_loss: 0.0111\n",
      "Epoch 17/100\n",
      "11269/11269 [==============================] - 32s 3ms/step - loss: 0.0129 - val_loss: 0.0110\n",
      "Epoch 18/100\n",
      "11269/11269 [==============================] - 30s 3ms/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 19/100\n",
      "11269/11269 [==============================] - 29s 3ms/step - loss: 0.0129 - val_loss: 0.0111\n",
      "Epoch 20/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0129 - val_loss: 0.0111\n",
      "Epoch 21/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0129 - val_loss: 0.0109\n",
      "13147/13147 [==============================] - 17s 1ms/step\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.6000000000000001, Threshold: 97, Best Epoch 11 f1 score: 0.17\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97    400666\n",
      "           1       0.22      0.14      0.17     20033\n",
      "\n",
      "    accuracy                           0.94    420699\n",
      "   macro avg       0.59      0.56      0.57    420699\n",
      "weighted avg       0.92      0.94      0.93    420699\n",
      "\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.6000000000000001, Threshold: 98, Best Epoch 11 f1 score: 0.15\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97    400666\n",
      "           1       0.25      0.10      0.15     20033\n",
      "\n",
      "    accuracy                           0.94    420699\n",
      "   macro avg       0.60      0.54      0.56    420699\n",
      "weighted avg       0.92      0.94      0.93    420699\n",
      "\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.6000000000000001, Threshold: 99, Best Epoch 11 f1 score: 0.11\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    400666\n",
      "           1       0.30      0.06      0.11     20033\n",
      "\n",
      "    accuracy                           0.95    420699\n",
      "   macro avg       0.63      0.53      0.54    420699\n",
      "weighted avg       0.92      0.95      0.93    420699\n",
      "\n",
      "Epoch 1/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0256 - val_loss: 0.0251\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0223 - val_loss: 0.0203\n",
      "Epoch 3/100\n",
      "11269/11269 [==============================] - 31s 3ms/step - loss: 0.0214 - val_loss: 0.0191\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 27s 2ms/step - loss: 0.0210 - val_loss: 0.0193\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 28s 2ms/step - loss: 0.0208 - val_loss: 0.0190\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0208 - val_loss: 0.0195\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0207 - val_loss: 0.0194\n",
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0208 - val_loss: 0.0195\n",
      "Epoch 9/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0208 - val_loss: 0.0199\n",
      "Epoch 10/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0209 - val_loss: 0.0199\n",
      "Epoch 11/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0210 - val_loss: 0.0197\n",
      "Epoch 12/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0210 - val_loss: 0.0197\n",
      "Epoch 13/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0211 - val_loss: 0.0205\n",
      "Epoch 14/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0213 - val_loss: 0.0198\n",
      "Epoch 15/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0213 - val_loss: 0.0198\n",
      "13147/13147 [==============================] - 15s 1ms/step\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.8, Threshold: 97, Best Epoch 5 f1 score: 0.14\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97    400666\n",
      "           1       0.18      0.11      0.14     20033\n",
      "\n",
      "    accuracy                           0.93    420699\n",
      "   macro avg       0.57      0.54      0.55    420699\n",
      "weighted avg       0.92      0.93      0.93    420699\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S.S.: 0.05, Dropout: 0.8, Threshold: 98, Best Epoch 5 f1 score: 0.11\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97    400666\n",
      "           1       0.19      0.08      0.11     20033\n",
      "\n",
      "    accuracy                           0.94    420699\n",
      "   macro avg       0.57      0.53      0.54    420699\n",
      "weighted avg       0.92      0.94      0.93    420699\n",
      "\n",
      "\n",
      "S.S.: 0.05, Dropout: 0.8, Threshold: 99, Best Epoch 5 f1 score: 0.08\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    400666\n",
      "           1       0.23      0.05      0.08     20033\n",
      "\n",
      "    accuracy                           0.95    420699\n",
      "   macro avg       0.59      0.52      0.53    420699\n",
      "weighted avg       0.92      0.95      0.93    420699\n",
      "\n",
      "Epoch 1/100\n",
      "11269/11269 [==============================] - 17s 1ms/step - loss: 0.0012 - val_loss: 2.7848e-04\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 17s 2ms/step - loss: 2.2331e-04 - val_loss: 1.8607e-04\n",
      "Epoch 3/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 2.1027e-04 - val_loss: 1.9293e-04\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 18s 2ms/step - loss: 1.9098e-04 - val_loss: 2.0004e-04\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 18s 2ms/step - loss: 1.6797e-04 - val_loss: 1.1917e-04\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 1.4936e-04 - val_loss: 1.2739e-04\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 17s 2ms/step - loss: 0.0021 - val_loss: 0.0075\n",
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 17s 1ms/step - loss: 0.0022 - val_loss: 1.0306e-04\n",
      "Epoch 9/100\n",
      "11269/11269 [==============================] - 17s 1ms/step - loss: 1.0708e-04 - val_loss: 1.3073e-04\n",
      "Epoch 10/100\n",
      "11269/11269 [==============================] - 19s 2ms/step - loss: 1.2415e-04 - val_loss: 1.0310e-04\n",
      "Epoch 11/100\n",
      "11269/11269 [==============================] - 17s 2ms/step - loss: 1.1116e-04 - val_loss: 1.0401e-04\n",
      "Epoch 12/100\n",
      "11269/11269 [==============================] - 17s 2ms/step - loss: 1.0601e-04 - val_loss: 8.3860e-05\n",
      "Epoch 13/100\n",
      "11269/11269 [==============================] - 20s 2ms/step - loss: 9.6996e-05 - val_loss: 8.2743e-05\n",
      "Epoch 14/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 1.1155e-04 - val_loss: 9.3975e-05\n",
      "Epoch 15/100\n",
      "11269/11269 [==============================] - 17s 2ms/step - loss: 9.1673e-05 - val_loss: 7.9784e-05\n",
      "Epoch 16/100\n",
      "11269/11269 [==============================] - 18s 2ms/step - loss: 8.9675e-05 - val_loss: 7.6877e-05\n",
      "Epoch 17/100\n",
      "11269/11269 [==============================] - 19s 2ms/step - loss: 9.2763e-05 - val_loss: 9.4519e-05\n",
      "Epoch 18/100\n",
      "11269/11269 [==============================] - 17s 1ms/step - loss: 9.0151e-05 - val_loss: 7.3982e-05\n",
      "Epoch 19/100\n",
      "11269/11269 [==============================] - 17s 1ms/step - loss: 8.9974e-05 - val_loss: 7.8321e-05\n",
      "Epoch 20/100\n",
      "11269/11269 [==============================] - 17s 2ms/step - loss: 8.7035e-05 - val_loss: 8.1371e-05\n",
      "Epoch 21/100\n",
      "11269/11269 [==============================] - 17s 2ms/step - loss: 8.9616e-05 - val_loss: 6.8899e-05\n",
      "Epoch 22/100\n",
      "11269/11269 [==============================] - 18s 2ms/step - loss: 6.8124e-05 - val_loss: 5.7953e-05\n",
      "Epoch 23/100\n",
      "11269/11269 [==============================] - 19s 2ms/step - loss: 7.1035e-05 - val_loss: 5.3344e-05\n",
      "Epoch 24/100\n",
      "11269/11269 [==============================] - 18s 2ms/step - loss: 7.1656e-05 - val_loss: 6.3729e-05\n",
      "Epoch 25/100\n",
      "11269/11269 [==============================] - 17s 2ms/step - loss: 6.0451e-05 - val_loss: 5.6629e-05\n",
      "Epoch 26/100\n",
      "11269/11269 [==============================] - 17s 1ms/step - loss: 6.7641e-05 - val_loss: 5.5570e-05\n",
      "Epoch 27/100\n",
      "11269/11269 [==============================] - 17s 1ms/step - loss: 6.4094e-05 - val_loss: 5.4144e-05\n",
      "Epoch 28/100\n",
      "11269/11269 [==============================] - 17s 2ms/step - loss: 6.5074e-05 - val_loss: 6.8519e-05\n",
      "Epoch 29/100\n",
      "11269/11269 [==============================] - 18s 2ms/step - loss: 9.5834e-05 - val_loss: 8.8055e-05\n",
      "Epoch 30/100\n",
      "11269/11269 [==============================] - 18s 2ms/step - loss: 7.9737e-05 - val_loss: 7.0544e-05\n",
      "Epoch 31/100\n",
      "11269/11269 [==============================] - 18s 2ms/step - loss: 7.2703e-05 - val_loss: 6.3360e-05\n",
      "Epoch 32/100\n",
      "11269/11269 [==============================] - 17s 2ms/step - loss: 9.5350e-05 - val_loss: 7.3837e-04\n",
      "Epoch 33/100\n",
      "11269/11269 [==============================] - 17s 2ms/step - loss: 8.8071e-05 - val_loss: 7.9714e-05\n",
      "14399/14399 [==============================] - 13s 870us/step\n",
      "\n",
      "S.S.: 0.15, Dropout: 0.0, Threshold: 97, Best Epoch 23 f1 score: 0.29\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94    400666\n",
      "           1       0.79      0.18      0.29     60099\n",
      "\n",
      "    accuracy                           0.89    460765\n",
      "   macro avg       0.84      0.59      0.62    460765\n",
      "weighted avg       0.88      0.89      0.85    460765\n",
      "\n",
      "\n",
      "S.S.: 0.15, Dropout: 0.0, Threshold: 98, Best Epoch 23 f1 score: 0.21\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94    400666\n",
      "           1       0.81      0.12      0.21     60099\n",
      "\n",
      "    accuracy                           0.88    460765\n",
      "   macro avg       0.85      0.56      0.58    460765\n",
      "weighted avg       0.87      0.88      0.84    460765\n",
      "\n",
      "\n",
      "S.S.: 0.15, Dropout: 0.0, Threshold: 99, Best Epoch 23 f1 score: 0.12\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93    400666\n",
      "           1       0.85      0.06      0.12     60099\n",
      "\n",
      "    accuracy                           0.88    460765\n",
      "   macro avg       0.86      0.53      0.53    460765\n",
      "weighted avg       0.87      0.88      0.83    460765\n",
      "\n",
      "Epoch 1/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0070 - val_loss: 0.0031\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 32s 3ms/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 3/100\n",
      "11269/11269 [==============================] - 30s 3ms/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 9/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 10/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 11/100\n",
      "11269/11269 [==============================] - 27s 2ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 12/100\n",
      "11269/11269 [==============================] - 29s 3ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 13/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 14/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 15/100\n",
      "11269/11269 [==============================] - 2079s 184ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 16/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 17/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 18/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 19/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 20/100\n",
      "11269/11269 [==============================] - 21s 2ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 21/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 22/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11269/11269 [==============================] - 849s 75ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 24/100\n",
      "11269/11269 [==============================] - 38s 3ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 25/100\n",
      "11269/11269 [==============================] - 33s 3ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "14399/14399 [==============================] - 27s 2ms/step\n",
      "\n",
      "S.S.: 0.15, Dropout: 0.2, Threshold: 97, Best Epoch 15 f1 score: 0.25\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.93    400666\n",
      "           1       0.68      0.16      0.25     60099\n",
      "\n",
      "    accuracy                           0.88    460765\n",
      "   macro avg       0.78      0.57      0.59    460765\n",
      "weighted avg       0.86      0.88      0.85    460765\n",
      "\n",
      "\n",
      "S.S.: 0.15, Dropout: 0.2, Threshold: 98, Best Epoch 15 f1 score: 0.19\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93    400666\n",
      "           1       0.71      0.11      0.19     60099\n",
      "\n",
      "    accuracy                           0.88    460765\n",
      "   macro avg       0.79      0.55      0.56    460765\n",
      "weighted avg       0.86      0.88      0.84    460765\n",
      "\n",
      "\n",
      "S.S.: 0.15, Dropout: 0.2, Threshold: 99, Best Epoch 15 f1 score: 0.11\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93    400666\n",
      "           1       0.74      0.06      0.11     60099\n",
      "\n",
      "    accuracy                           0.87    460765\n",
      "   macro avg       0.81      0.53      0.52    460765\n",
      "weighted avg       0.86      0.87      0.82    460765\n",
      "\n",
      "Epoch 1/100\n",
      "11269/11269 [==============================] - 58s 5ms/step - loss: 0.0117 - val_loss: 0.0068\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 43s 4ms/step - loss: 0.0085 - val_loss: 0.0057\n",
      "Epoch 3/100\n",
      "11269/11269 [==============================] - 47s 4ms/step - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 43s 4ms/step - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 48s 4ms/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 59s 5ms/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 50s 4ms/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 45s 4ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 9/100\n",
      "11269/11269 [==============================] - 59s 5ms/step - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 10/100\n",
      "11269/11269 [==============================] - 54s 5ms/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 11/100\n",
      "11269/11269 [==============================] - 46s 4ms/step - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 12/100\n",
      "11269/11269 [==============================] - 53s 5ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 13/100\n",
      "11269/11269 [==============================] - 43s 4ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 14/100\n",
      "11269/11269 [==============================] - 39s 3ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 15/100\n",
      "11269/11269 [==============================] - 38s 3ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 16/100\n",
      "11269/11269 [==============================] - 49s 4ms/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 17/100\n",
      "11269/11269 [==============================] - 47s 4ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 18/100\n",
      "11269/11269 [==============================] - 42s 4ms/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 19/100\n",
      "11269/11269 [==============================] - 50s 4ms/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 20/100\n",
      "11269/11269 [==============================] - 44s 4ms/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 21/100\n",
      "11269/11269 [==============================] - 57s 5ms/step - loss: 0.0071 - val_loss: 0.0051\n",
      "14399/14399 [==============================] - 25s 2ms/step\n",
      "\n",
      "S.S.: 0.15, Dropout: 0.4, Threshold: 97, Best Epoch 11 f1 score: 0.17\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93    400666\n",
      "           1       0.46      0.11      0.17     60099\n",
      "\n",
      "    accuracy                           0.87    460765\n",
      "   macro avg       0.67      0.54      0.55    460765\n",
      "weighted avg       0.83      0.87      0.83    460765\n",
      "\n",
      "\n",
      "S.S.: 0.15, Dropout: 0.4, Threshold: 98, Best Epoch 11 f1 score: 0.13\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93    400666\n",
      "           1       0.49      0.07      0.13     60099\n",
      "\n",
      "    accuracy                           0.87    460765\n",
      "   macro avg       0.68      0.53      0.53    460765\n",
      "weighted avg       0.83      0.87      0.82    460765\n",
      "\n",
      "\n",
      "S.S.: 0.15, Dropout: 0.4, Threshold: 99, Best Epoch 11 f1 score: 0.08\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93    400666\n",
      "           1       0.55      0.04      0.08     60099\n",
      "\n",
      "    accuracy                           0.87    460765\n",
      "   macro avg       0.71      0.52      0.50    460765\n",
      "weighted avg       0.83      0.87      0.82    460765\n",
      "\n",
      "Epoch 1/100\n",
      "11269/11269 [==============================] - 54s 5ms/step - loss: 0.0167 - val_loss: 0.0125\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 46s 4ms/step - loss: 0.0140 - val_loss: 0.0121\n",
      "Epoch 3/100\n",
      "11269/11269 [==============================] - 53s 5ms/step - loss: 0.0137 - val_loss: 0.0121\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 49s 4ms/step - loss: 0.0135 - val_loss: 0.0121\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 48s 4ms/step - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 45s 4ms/step - loss: 0.0136 - val_loss: 0.0121\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 59s 5ms/step - loss: 0.0134 - val_loss: 0.0122\n",
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 60s 5ms/step - loss: 0.0135 - val_loss: 0.0122\n",
      "Epoch 9/100\n",
      "11269/11269 [==============================] - 60s 5ms/step - loss: 0.0135 - val_loss: 0.0121\n",
      "Epoch 10/100\n",
      "11269/11269 [==============================] - 62s 5ms/step - loss: 0.0136 - val_loss: 0.0122\n",
      "Epoch 11/100\n",
      "11269/11269 [==============================] - 507s 45ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 12/100\n",
      "11269/11269 [==============================] - 45s 4ms/step - loss: 0.0135 - val_loss: 0.0122\n",
      "Epoch 13/100\n",
      "11269/11269 [==============================] - 57s 5ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 14/100\n",
      "11269/11269 [==============================] - 53s 5ms/step - loss: 0.0136 - val_loss: 0.0124\n",
      "Epoch 15/100\n",
      "11269/11269 [==============================] - 50s 4ms/step - loss: 0.0136 - val_loss: 0.0123\n",
      "14399/14399 [==============================] - 30s 2ms/step\n",
      "\n",
      "S.S.: 0.15, Dropout: 0.6000000000000001, Threshold: 97, Best Epoch 5 f1 score: 0.19\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93    400666\n",
      "           1       0.51      0.12      0.19     60099\n",
      "\n",
      "    accuracy                           0.87    460765\n",
      "   macro avg       0.70      0.55      0.56    460765\n",
      "weighted avg       0.83      0.87      0.83    460765\n",
      "\n",
      "\n",
      "S.S.: 0.15, Dropout: 0.6000000000000001, Threshold: 98, Best Epoch 5 f1 score: 0.14\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93    400666\n",
      "           1       0.54      0.08      0.14     60099\n",
      "\n",
      "    accuracy                           0.87    460765\n",
      "   macro avg       0.71      0.54      0.54    460765\n",
      "weighted avg       0.83      0.87      0.83    460765\n",
      "\n",
      "\n",
      "S.S.: 0.15, Dropout: 0.6000000000000001, Threshold: 99, Best Epoch 5 f1 score: 0.09\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93    400666\n",
      "           1       0.62      0.05      0.09     60099\n",
      "\n",
      "    accuracy                           0.87    460765\n",
      "   macro avg       0.75      0.52      0.51    460765\n",
      "weighted avg       0.84      0.87      0.82    460765\n",
      "\n",
      "Epoch 1/100\n",
      "11269/11269 [==============================] - 55s 5ms/step - loss: 0.0255 - val_loss: 0.0251\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 52s 5ms/step - loss: 0.0223 - val_loss: 0.0204\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11269/11269 [==============================] - 47s 4ms/step - loss: 0.0212 - val_loss: 0.0191\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 51s 4ms/step - loss: 0.0208 - val_loss: 0.0190\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 51s 5ms/step - loss: 0.0207 - val_loss: 0.0191\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 46s 4ms/step - loss: 0.0206 - val_loss: 0.0191\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 43s 4ms/step - loss: 0.0206 - val_loss: 0.0194\n",
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 51s 4ms/step - loss: 0.0206 - val_loss: 0.0198\n",
      "Epoch 9/100\n",
      "11269/11269 [==============================] - 54s 5ms/step - loss: 0.0207 - val_loss: 0.0199\n",
      "Epoch 10/100\n",
      "11269/11269 [==============================] - 47s 4ms/step - loss: 0.0207 - val_loss: 0.0198\n",
      "Epoch 11/100\n",
      "11269/11269 [==============================] - 49s 4ms/step - loss: 0.0209 - val_loss: 0.0196\n",
      "Epoch 12/100\n",
      "11269/11269 [==============================] - 51s 5ms/step - loss: 0.0210 - val_loss: 0.0196\n",
      "Epoch 13/100\n",
      "11269/11269 [==============================] - 48s 4ms/step - loss: 0.0212 - val_loss: 0.0194\n",
      "Epoch 14/100\n",
      "11269/11269 [==============================] - 52s 5ms/step - loss: 0.0213 - val_loss: 0.0192\n",
      "14399/14399 [==============================] - 27s 2ms/step\n",
      "\n",
      "S.S.: 0.15, Dropout: 0.8, Threshold: 97, Best Epoch 4 f1 score: 0.15\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93    400666\n",
      "           1       0.41      0.09      0.15     60099\n",
      "\n",
      "    accuracy                           0.86    460765\n",
      "   macro avg       0.64      0.54      0.54    460765\n",
      "weighted avg       0.82      0.86      0.83    460765\n",
      "\n",
      "\n",
      "S.S.: 0.15, Dropout: 0.8, Threshold: 98, Best Epoch 4 f1 score: 0.12\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93    400666\n",
      "           1       0.44      0.07      0.12     60099\n",
      "\n",
      "    accuracy                           0.87    460765\n",
      "   macro avg       0.66      0.53      0.52    460765\n",
      "weighted avg       0.82      0.87      0.82    460765\n",
      "\n",
      "\n",
      "S.S.: 0.15, Dropout: 0.8, Threshold: 99, Best Epoch 4 f1 score: 0.07\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93    400666\n",
      "           1       0.51      0.04      0.07     60099\n",
      "\n",
      "    accuracy                           0.87    460765\n",
      "   macro avg       0.69      0.52      0.50    460765\n",
      "weighted avg       0.83      0.87      0.82    460765\n",
      "\n",
      "Epoch 1/100\n",
      "11269/11269 [==============================] - 35s 3ms/step - loss: 0.0011 - val_loss: 2.6042e-04\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 34s 3ms/step - loss: 2.3417e-04 - val_loss: 1.8342e-04\n",
      "Epoch 3/100\n",
      "11269/11269 [==============================] - 33s 3ms/step - loss: 1.6547e-04 - val_loss: 1.3912e-04\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 34s 3ms/step - loss: 0.0032 - val_loss: 0.0075\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 35s 3ms/step - loss: 0.0057 - val_loss: 0.0075\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 33s 3ms/step - loss: 0.0026 - val_loss: 1.3410e-04\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 33s 3ms/step - loss: 1.2483e-04 - val_loss: 9.9153e-05\n",
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 29s 3ms/step - loss: 1.4151e-04 - val_loss: 1.8598e-04\n",
      "Epoch 9/100\n",
      "11269/11269 [==============================] - 28s 3ms/step - loss: 1.1992e-04 - val_loss: 9.6523e-05\n",
      "Epoch 10/100\n",
      "11269/11269 [==============================] - 31s 3ms/step - loss: 3.2373e-04 - val_loss: 0.0075\n",
      "Epoch 11/100\n",
      "11269/11269 [==============================] - 32s 3ms/step - loss: 0.0035 - val_loss: 0.0075\n",
      "Epoch 12/100\n",
      "11269/11269 [==============================] - 38s 3ms/step - loss: 0.0013 - val_loss: 9.8557e-05\n",
      "Epoch 13/100\n",
      "11269/11269 [==============================] - 35s 3ms/step - loss: 9.8991e-04 - val_loss: 1.1966e-04\n",
      "Epoch 14/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 1.0457e-04 - val_loss: 8.2728e-05\n",
      "Epoch 15/100\n",
      "11269/11269 [==============================] - 35s 3ms/step - loss: 0.0027 - val_loss: 0.0075\n",
      "Epoch 16/100\n",
      "11269/11269 [==============================] - 34s 3ms/step - loss: 0.0033 - val_loss: 1.0101e-04\n",
      "Epoch 17/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 4.9823e-04 - val_loss: 0.0075\n",
      "Epoch 18/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0040 - val_loss: 1.0042e-04\n",
      "Epoch 19/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 1.2774e-04 - val_loss: 1.1082e-04\n",
      "Epoch 20/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 3.2577e-04 - val_loss: 0.0075\n",
      "Epoch 21/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0024 - val_loss: 1.0282e-04\n",
      "Epoch 22/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 1.1111e-04 - val_loss: 9.9778e-05\n",
      "Epoch 23/100\n",
      "11269/11269 [==============================] - 30s 3ms/step - loss: 1.0351e-04 - val_loss: 8.9233e-05\n",
      "Epoch 24/100\n",
      "11269/11269 [==============================] - 37s 3ms/step - loss: 0.0012 - val_loss: 8.7029e-05\n",
      "15651/15651 [==============================] - 31s 2ms/step\n",
      "\n",
      "S.S.: 0.25, Dropout: 0.0, Threshold: 97, Best Epoch 14 f1 score: 0.23\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90    400666\n",
      "           1       0.87      0.13      0.23    100166\n",
      "\n",
      "    accuracy                           0.82    500832\n",
      "   macro avg       0.85      0.56      0.56    500832\n",
      "weighted avg       0.83      0.82      0.77    500832\n",
      "\n",
      "\n",
      "S.S.: 0.25, Dropout: 0.0, Threshold: 98, Best Epoch 14 f1 score: 0.16\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90    400666\n",
      "           1       0.89      0.09      0.16    100166\n",
      "\n",
      "    accuracy                           0.82    500832\n",
      "   macro avg       0.85      0.54      0.53    500832\n",
      "weighted avg       0.83      0.82      0.75    500832\n",
      "\n",
      "\n",
      "S.S.: 0.25, Dropout: 0.0, Threshold: 99, Best Epoch 14 f1 score: 0.09\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89    400666\n",
      "           1       0.91      0.05      0.09    100166\n",
      "\n",
      "    accuracy                           0.81    500832\n",
      "   macro avg       0.86      0.52      0.49    500832\n",
      "weighted avg       0.83      0.81      0.73    500832\n",
      "\n",
      "Epoch 1/100\n",
      "11269/11269 [==============================] - 69s 6ms/step - loss: 0.0070 - val_loss: 0.0033\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 64s 6ms/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 3/100\n",
      "11269/11269 [==============================] - 2555s 227ms/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 31s 3ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 29s 3ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 32s 3ms/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 27s 2ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 9/100\n",
      "11269/11269 [==============================] - 33s 3ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 10/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 11/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 12/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 13/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 14/100\n",
      "11269/11269 [==============================] - 30s 3ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 15/100\n",
      "11269/11269 [==============================] - 29s 3ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 16/100\n",
      "11269/11269 [==============================] - 29s 3ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11269/11269 [==============================] - 30s 3ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 18/100\n",
      "11269/11269 [==============================] - 31s 3ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 19/100\n",
      "11269/11269 [==============================] - 28s 3ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 20/100\n",
      "11269/11269 [==============================] - 27s 2ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 21/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 22/100\n",
      "11269/11269 [==============================] - 33s 3ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 23/100\n",
      "11269/11269 [==============================] - 30s 3ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 24/100\n",
      "11269/11269 [==============================] - 30s 3ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 25/100\n",
      "11269/11269 [==============================] - 32s 3ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 26/100\n",
      "11269/11269 [==============================] - 39s 3ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 27/100\n",
      "11269/11269 [==============================] - 31s 3ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 28/100\n",
      "11269/11269 [==============================] - 29s 3ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 29/100\n",
      "11269/11269 [==============================] - 40s 4ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 30/100\n",
      "11269/11269 [==============================] - 54s 5ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 31/100\n",
      "11269/11269 [==============================] - 42s 4ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 32/100\n",
      "11269/11269 [==============================] - 37s 3ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 33/100\n",
      "11269/11269 [==============================] - 33s 3ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 34/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 35/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 36/100\n",
      "11269/11269 [==============================] - 32s 3ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 37/100\n",
      "11269/11269 [==============================] - 31s 3ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 38/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "15651/15651 [==============================] - 15s 958us/step\n",
      "\n",
      "S.S.: 0.25, Dropout: 0.2, Threshold: 97, Best Epoch 28 f1 score: 0.2\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90    400666\n",
      "           1       0.76      0.11      0.20    100166\n",
      "\n",
      "    accuracy                           0.82    500832\n",
      "   macro avg       0.79      0.55      0.55    500832\n",
      "weighted avg       0.81      0.82      0.76    500832\n",
      "\n",
      "\n",
      "S.S.: 0.25, Dropout: 0.2, Threshold: 98, Best Epoch 28 f1 score: 0.14\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89    400666\n",
      "           1       0.78      0.08      0.14    100166\n",
      "\n",
      "    accuracy                           0.81    500832\n",
      "   macro avg       0.80      0.54      0.52    500832\n",
      "weighted avg       0.81      0.81      0.74    500832\n",
      "\n",
      "\n",
      "S.S.: 0.25, Dropout: 0.2, Threshold: 99, Best Epoch 28 f1 score: 0.08\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89    400666\n",
      "           1       0.82      0.04      0.08    100166\n",
      "\n",
      "    accuracy                           0.81    500832\n",
      "   macro avg       0.81      0.52      0.48    500832\n",
      "weighted avg       0.81      0.81      0.73    500832\n",
      "\n",
      "Epoch 1/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0114 - val_loss: 0.0063\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 28s 2ms/step - loss: 0.0082 - val_loss: 0.0058\n",
      "Epoch 3/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0073 - val_loss: 0.0054\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 27s 2ms/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 27s 2ms/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 9/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 10/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 11/100\n",
      "11269/11269 [==============================] - 28s 2ms/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 12/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 13/100\n",
      "11269/11269 [==============================] - 29s 3ms/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 14/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 15/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 16/100\n",
      "11269/11269 [==============================] - 30s 3ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 17/100\n",
      "11269/11269 [==============================] - 23s 2ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 18/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 19/100\n",
      "11269/11269 [==============================] - 50s 4ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 20/100\n",
      "11269/11269 [==============================] - 30s 3ms/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 21/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 22/100\n",
      "11269/11269 [==============================] - 28s 2ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 23/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 24/100\n",
      "11269/11269 [==============================] - 32s 3ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 25/100\n",
      "11269/11269 [==============================] - 39s 3ms/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 26/100\n",
      "11269/11269 [==============================] - 28s 2ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 27/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 28/100\n",
      "11269/11269 [==============================] - 30s 3ms/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 29/100\n",
      "11269/11269 [==============================] - 29s 3ms/step - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 30/100\n",
      "11269/11269 [==============================] - 31s 3ms/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 31/100\n",
      "11269/11269 [==============================] - 30s 3ms/step - loss: 0.0071 - val_loss: 0.0049\n",
      "15651/15651 [==============================] - 22s 1ms/step\n",
      "\n",
      "S.S.: 0.25, Dropout: 0.4, Threshold: 97, Best Epoch 21 f1 score: 0.16\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89    400666\n",
      "           1       0.62      0.09      0.16    100166\n",
      "\n",
      "    accuracy                           0.81    500832\n",
      "   macro avg       0.72      0.54      0.53    500832\n",
      "weighted avg       0.77      0.81      0.75    500832\n",
      "\n",
      "\n",
      "S.S.: 0.25, Dropout: 0.4, Threshold: 98, Best Epoch 21 f1 score: 0.12\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89    400666\n",
      "           1       0.66      0.07      0.12    100166\n",
      "\n",
      "    accuracy                           0.81    500832\n",
      "   macro avg       0.73      0.53      0.51    500832\n",
      "weighted avg       0.78      0.81      0.74    500832\n",
      "\n",
      "\n",
      "S.S.: 0.25, Dropout: 0.4, Threshold: 99, Best Epoch 21 f1 score: 0.07\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89    400666\n",
      "           1       0.72      0.04      0.07    100166\n",
      "\n",
      "    accuracy                           0.80    500832\n",
      "   macro avg       0.76      0.52      0.48    500832\n",
      "weighted avg       0.79      0.80      0.73    500832\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11269/11269 [==============================] - 32s 3ms/step - loss: 0.0167 - val_loss: 0.0122\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0139 - val_loss: 0.0122\n",
      "Epoch 3/100\n",
      "11269/11269 [==============================] - 27s 2ms/step - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 30s 3ms/step - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 31s 3ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 32s 3ms/step - loss: 0.0134 - val_loss: 0.0122\n",
      "Epoch 9/100\n",
      "11269/11269 [==============================] - 42s 4ms/step - loss: 0.0134 - val_loss: 0.0122\n",
      "Epoch 10/100\n",
      "11269/11269 [==============================] - 31s 3ms/step - loss: 0.0133 - val_loss: 0.0123\n",
      "Epoch 11/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 12/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 13/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 14/100\n",
      "11269/11269 [==============================] - 28s 2ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "11269/11269 [==============================] - 27s 2ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 16/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 17/100\n",
      "11269/11269 [==============================] - 29s 3ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 18/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 19/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0132 - val_loss: 0.0120\n",
      "Epoch 20/100\n",
      "11269/11269 [==============================] - 24s 2ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 21/100\n",
      "11269/11269 [==============================] - 31s 3ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 22/100\n",
      "11269/11269 [==============================] - 28s 2ms/step - loss: 0.0133 - val_loss: 0.0118\n",
      "Epoch 23/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0133 - val_loss: 0.0119\n",
      "Epoch 24/100\n",
      "11269/11269 [==============================] - 27s 2ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 25/100\n",
      "11269/11269 [==============================] - 27s 2ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 26/100\n",
      "11269/11269 [==============================] - 28s 2ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 27/100\n",
      "11269/11269 [==============================] - 22s 2ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 28/100\n",
      "11269/11269 [==============================] - 31s 3ms/step - loss: 0.0134 - val_loss: 0.0119\n",
      "Epoch 29/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0134 - val_loss: 0.0120\n",
      "Epoch 30/100\n",
      "11269/11269 [==============================] - 25s 2ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 31/100\n",
      "11269/11269 [==============================] - 34s 3ms/step - loss: 0.0134 - val_loss: 0.0120\n",
      "Epoch 32/100\n",
      "11269/11269 [==============================] - 30s 3ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "15651/15651 [==============================] - 17s 1ms/step\n",
      "\n",
      "S.S.: 0.25, Dropout: 0.6000000000000001, Threshold: 97, Best Epoch 22 f1 score: 0.17\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89    400666\n",
      "           1       0.64      0.10      0.17    100166\n",
      "\n",
      "    accuracy                           0.81    500832\n",
      "   macro avg       0.73      0.54      0.53    500832\n",
      "weighted avg       0.78      0.81      0.75    500832\n",
      "\n",
      "\n",
      "S.S.: 0.25, Dropout: 0.6000000000000001, Threshold: 98, Best Epoch 22 f1 score: 0.12\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89    400666\n",
      "           1       0.68      0.07      0.12    100166\n",
      "\n",
      "    accuracy                           0.81    500832\n",
      "   macro avg       0.74      0.53      0.51    500832\n",
      "weighted avg       0.78      0.81      0.74    500832\n",
      "\n",
      "\n",
      "S.S.: 0.25, Dropout: 0.6000000000000001, Threshold: 99, Best Epoch 22 f1 score: 0.07\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89    400666\n",
      "           1       0.74      0.04      0.07    100166\n",
      "\n",
      "    accuracy                           0.80    500832\n",
      "   macro avg       0.77      0.52      0.48    500832\n",
      "weighted avg       0.79      0.80      0.73    500832\n",
      "\n",
      "Epoch 1/100\n",
      "11269/11269 [==============================] - 31s 3ms/step - loss: 0.0255 - val_loss: 0.0227\n",
      "Epoch 2/100\n",
      "11269/11269 [==============================] - 34s 3ms/step - loss: 0.0222 - val_loss: 0.0207\n",
      "Epoch 3/100\n",
      "11269/11269 [==============================] - 32s 3ms/step - loss: 0.0214 - val_loss: 0.0192\n",
      "Epoch 4/100\n",
      "11269/11269 [==============================] - 28s 2ms/step - loss: 0.0208 - val_loss: 0.0187\n",
      "Epoch 5/100\n",
      "11269/11269 [==============================] - 27s 2ms/step - loss: 0.0204 - val_loss: 0.0189\n",
      "Epoch 6/100\n",
      "11269/11269 [==============================] - 33s 3ms/step - loss: 0.0203 - val_loss: 0.0190\n",
      "Epoch 7/100\n",
      "11269/11269 [==============================] - 35s 3ms/step - loss: 0.0203 - val_loss: 0.0190\n",
      "Epoch 8/100\n",
      "11269/11269 [==============================] - 29s 3ms/step - loss: 0.0203 - val_loss: 0.0189\n",
      "Epoch 9/100\n",
      "11269/11269 [==============================] - 33s 3ms/step - loss: 0.0204 - val_loss: 0.0189\n",
      "Epoch 10/100\n",
      "11269/11269 [==============================] - 30s 3ms/step - loss: 0.0204 - val_loss: 0.0195\n",
      "Epoch 11/100\n",
      "11269/11269 [==============================] - 33s 3ms/step - loss: 0.0204 - val_loss: 0.0193\n",
      "Epoch 12/100\n",
      "11269/11269 [==============================] - 26s 2ms/step - loss: 0.0203 - val_loss: 0.0190\n",
      "Epoch 13/100\n",
      "11269/11269 [==============================] - 29s 3ms/step - loss: 0.0203 - val_loss: 0.0189\n",
      "Epoch 14/100\n",
      "11269/11269 [==============================] - 29s 3ms/step - loss: 0.0203 - val_loss: 0.0193\n",
      "15651/15651 [==============================] - 17s 1ms/step\n",
      "\n",
      "S.S.: 0.25, Dropout: 0.8, Threshold: 97, Best Epoch 4 f1 score: 0.14\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89    400666\n",
      "           1       0.54      0.08      0.14    100166\n",
      "\n",
      "    accuracy                           0.80    500832\n",
      "   macro avg       0.67      0.53      0.51    500832\n",
      "weighted avg       0.76      0.80      0.74    500832\n",
      "\n",
      "\n",
      "S.S.: 0.25, Dropout: 0.8, Threshold: 98, Best Epoch 4 f1 score: 0.11\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89    400666\n",
      "           1       0.58      0.06      0.11    100166\n",
      "\n",
      "    accuracy                           0.80    500832\n",
      "   macro avg       0.69      0.52      0.50    500832\n",
      "weighted avg       0.76      0.80      0.73    500832\n",
      "\n",
      "\n",
      "S.S.: 0.25, Dropout: 0.8, Threshold: 99, Best Epoch 4 f1 score: 0.06\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89    400666\n",
      "           1       0.66      0.03      0.06    100166\n",
      "\n",
      "    accuracy                           0.80    500832\n",
      "   macro avg       0.73      0.51      0.48    500832\n",
      "weighted avg       0.78      0.80      0.72    500832\n",
      "\n",
      "Best:\n",
      "(5, 0, 97, 13)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97    400666\n",
      "           1       0.48      0.30      0.37     20033\n",
      "\n",
      "    accuracy                           0.95    420699\n",
      "   macro avg       0.72      0.64      0.67    420699\n",
      "weighted avg       0.94      0.95      0.95    420699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best = (0, 0, 0, None)\n",
    "# Oversample the minority group to make the data more balanced\n",
    "for ss in range(5, 35, 10):\n",
    "    smote = SMOTE(sampling_strategy=ss*0.01, random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(skin_cancer_df.iloc[:, 1:], skin_cancer_df.iloc[:, 0])\n",
    "\n",
    "    # Split the data - training is non-cancerous, test is on all patients to detect anomalies\n",
    "    X_train = X_resampled[y_resampled == 0]\n",
    "    X_test = X_resampled\n",
    "\n",
    "    # Scale the data between 0 and 1\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Build the autoencoder model - dropout of 5 works best\n",
    "    for d in range(0, 10, 2):\n",
    "        \n",
    "        autoencoder = Sequential([\n",
    "            Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
    "            #BatchNormalization(),  # Apply BatchNormalization\n",
    "            #Activation('relu'),     # Then apply activation function\n",
    "            Dropout(d*0.1),           # Optional dropout for regularization\n",
    "\n",
    "            Dense(64, activation='relu'),\n",
    "            #BatchNormalization(),\n",
    "            #Activation('relu'),\n",
    "            Dropout(d*0.1),\n",
    "\n",
    "            Dense(32, activation='relu'),\n",
    "            #BatchNormalization(),\n",
    "            #Activation('relu'),\n",
    "\n",
    "            Dense(64, activation='relu'),\n",
    "            #BatchNormalization(),\n",
    "            #Activation('relu'),\n",
    "            Dropout(d*0.1),\n",
    "\n",
    "            Dense(128, activation='relu'),\n",
    "            #BatchNormalization(),\n",
    "            #Activation('relu'),\n",
    "            Dropout(d*0.1),\n",
    "\n",
    "            Dense(X_train.shape[1], activation='sigmoid')  # Output layer should match input\n",
    "        ])\n",
    "\n",
    "        autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "        # Train the autoencoder using only the non-cancerous patients\n",
    "        history = autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, validation_split=0.1,\n",
    "                                 callbacks=[early_stopping])\n",
    "\n",
    "        # Find the epoch with the lowest validation loss\n",
    "        best_epoch = np.argmin(history.history['val_loss']) + 1  # Add 1 since epochs are 1-indexed\n",
    "        best_val_loss = np.min(history.history['val_loss'])\n",
    "\n",
    "        #print('Sampling Strategy:', ss*0.01)\n",
    "        #print('Dropout', d)\n",
    "        #print(f\"The best epoch is: {best_epoch}\")\n",
    "        #print(f\"The validation loss at the best epoch is: {best_val_loss}\")\n",
    "\n",
    "        # Calculate reconstruction error for each sample\n",
    "        reconstructed = autoencoder.predict(X_test)\n",
    "        reconstruction_error = np.mean(np.abs(reconstructed - X_test), axis=1)\n",
    "\n",
    "        # Threshold the reconstruction error to detect anomalies\n",
    "        # Can also try to expirement with this 98 val try values from 97 to 99?\n",
    "        for thresh in range(97, 100):\n",
    "            threshold = np.percentile(reconstruction_error, thresh)  # Set threshold (e.g., 99th percentile)\n",
    "            predictions_autoencoder = (reconstruction_error > threshold).astype(int)  # 1 = anomaly (cancer), 0 = normal\n",
    "            cr = classification_report(y_resampled, predictions_autoencoder)\n",
    "            f1_score = float(cr.split()[12])\n",
    "            print(f'\\nS.S.: {ss*.01}, Dropout: {d*.1}, Threshold: {thresh}, Best Epoch {best_epoch}',\n",
    "                  f'f1 score: {f1_score}\\n', cr)\n",
    "            if f1_score > best[2]:\n",
    "                best = (ss, d, thresh, best_epoch, f1_score, cr)\n",
    "\n",
    "print('Best:')\n",
    "print(best[:4])\n",
    "print(best[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5b1dfaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8875/8875 [==============================] - 25s 3ms/step - loss: 0.0155 - val_loss: 0.0082\n",
      "Epoch 2/100\n",
      "8875/8875 [==============================] - 26s 3ms/step - loss: 0.0115 - val_loss: 0.0077\n",
      "Epoch 3/100\n",
      "8875/8875 [==============================] - 33s 4ms/step - loss: 0.0108 - val_loss: 0.0074\n",
      "Epoch 4/100\n",
      "8875/8875 [==============================] - 26s 3ms/step - loss: 0.0104 - val_loss: 0.0066\n",
      "Epoch 5/100\n",
      "8875/8875 [==============================] - 35s 4ms/step - loss: 0.0100 - val_loss: 0.0065\n",
      "Epoch 6/100\n",
      "8875/8875 [==============================] - 26s 3ms/step - loss: 0.0098 - val_loss: 0.0064\n",
      "Epoch 7/100\n",
      "8875/8875 [==============================] - 35s 4ms/step - loss: 0.0097 - val_loss: 0.0064\n",
      "Epoch 8/100\n",
      "8875/8875 [==============================] - 26s 3ms/step - loss: 0.0096 - val_loss: 0.0062\n",
      "Epoch 9/100\n",
      "8875/8875 [==============================] - 27s 3ms/step - loss: 0.0096 - val_loss: 0.0062\n",
      "Epoch 10/100\n",
      "8875/8875 [==============================] - 26s 3ms/step - loss: 0.0095 - val_loss: 0.0062\n",
      "Epoch 11/100\n",
      "8875/8875 [==============================] - 34s 4ms/step - loss: 0.0094 - val_loss: 0.0062\n",
      "Epoch 12/100\n",
      "8875/8875 [==============================] - 27s 3ms/step - loss: 0.0094 - val_loss: 0.0062\n",
      "Epoch 13/100\n",
      "8875/8875 [==============================] - 32s 4ms/step - loss: 0.0094 - val_loss: 0.0061\n",
      "Epoch 14/100\n",
      "8875/8875 [==============================] - 29s 3ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 15/100\n",
      "8875/8875 [==============================] - 34s 4ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 16/100\n",
      "8875/8875 [==============================] - 26s 3ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 17/100\n",
      "8875/8875 [==============================] - 28s 3ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 18/100\n",
      "8875/8875 [==============================] - 26s 3ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 19/100\n",
      "8875/8875 [==============================] - 32s 4ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 20/100\n",
      "8875/8875 [==============================] - 28s 3ms/step - loss: 0.0093 - val_loss: 0.0060\n",
      "Epoch 21/100\n",
      "8875/8875 [==============================] - 28s 3ms/step - loss: 0.0093 - val_loss: 0.0060\n",
      "Epoch 22/100\n",
      "8875/8875 [==============================] - 27s 3ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 23/100\n",
      "8875/8875 [==============================] - 30s 3ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 24/100\n",
      "8875/8875 [==============================] - 30s 3ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 25/100\n",
      "8875/8875 [==============================] - 29s 3ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 26/100\n",
      "8875/8875 [==============================] - 33s 4ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 27/100\n",
      "8875/8875 [==============================] - 34s 4ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 28/100\n",
      "8875/8875 [==============================] - 28s 3ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 29/100\n",
      "8875/8875 [==============================] - 26s 3ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 30/100\n",
      "8875/8875 [==============================] - 25s 3ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 31/100\n",
      "8875/8875 [==============================] - 25s 3ms/step - loss: 0.0092 - val_loss: 0.0059\n",
      "Epoch 32/100\n",
      "8875/8875 [==============================] - 33s 4ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 33/100\n",
      "8875/8875 [==============================] - 25s 3ms/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 34/100\n",
      "8875/8875 [==============================] - 35s 4ms/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 35/100\n",
      "8875/8875 [==============================] - 25s 3ms/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Epoch 36/100\n",
      "8875/8875 [==============================] - 30s 3ms/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 37/100\n",
      "8875/8875 [==============================] - 29s 3ms/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 38/100\n",
      "8875/8875 [==============================] - 26s 3ms/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 39/100\n",
      "8875/8875 [==============================] - 26s 3ms/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 40/100\n",
      "8875/8875 [==============================] - 32s 4ms/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 41/100\n",
      "8875/8875 [==============================] - 26s 3ms/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Sampling Strategy: 0.05\n",
      "Dropout 5\n",
      "The best epoch is: 31\n",
      "The validation loss at the best epoch is: 0.005869598593562841\n",
      "2466/2466 [==============================] - 3s 1ms/step\n",
      "\n",
      "Dropout: 5\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     75125\n",
      "           1       0.19      0.08      0.11      3756\n",
      "\n",
      "    accuracy                           0.94     78881\n",
      "   macro avg       0.57      0.53      0.54     78881\n",
      "weighted avg       0.92      0.94      0.93     78881\n",
      "\n",
      "Epoch 1/100\n",
      "9720/9720 [==============================] - 29s 3ms/step - loss: 0.0154 - val_loss: 0.0090\n",
      "Epoch 2/100\n",
      "9720/9720 [==============================] - 31s 3ms/step - loss: 0.0116 - val_loss: 0.0080\n",
      "Epoch 3/100\n",
      "9720/9720 [==============================] - 7170s 738ms/step - loss: 0.0109 - val_loss: 0.0074\n",
      "Epoch 4/100\n",
      "9720/9720 [==============================] - 57s 6ms/step - loss: 0.0104 - val_loss: 0.0071\n",
      "Epoch 5/100\n",
      "9720/9720 [==============================] - 58s 6ms/step - loss: 0.0101 - val_loss: 0.0070\n",
      "Epoch 6/100\n",
      "9720/9720 [==============================] - 33s 3ms/step - loss: 0.0100 - val_loss: 0.0069\n",
      "Epoch 7/100\n",
      "9720/9720 [==============================] - 32s 3ms/step - loss: 0.0098 - val_loss: 0.0069\n",
      "Epoch 8/100\n",
      "9720/9720 [==============================] - 28s 3ms/step - loss: 0.0098 - val_loss: 0.0070\n",
      "Epoch 9/100\n",
      "9720/9720 [==============================] - 27s 3ms/step - loss: 0.0097 - val_loss: 0.0071\n",
      "Epoch 10/100\n",
      "9720/9720 [==============================] - 27s 3ms/step - loss: 0.0097 - val_loss: 0.0070\n",
      "Epoch 11/100\n",
      "9720/9720 [==============================] - 32s 3ms/step - loss: 0.0096 - val_loss: 0.0072\n",
      "Epoch 12/100\n",
      "9720/9720 [==============================] - 29s 3ms/step - loss: 0.0096 - val_loss: 0.0072\n",
      "Epoch 13/100\n",
      "9720/9720 [==============================] - 30s 3ms/step - loss: 0.0096 - val_loss: 0.0072\n",
      "Epoch 14/100\n",
      "9720/9720 [==============================] - 31s 3ms/step - loss: 0.0096 - val_loss: 0.0075\n",
      "Epoch 15/100\n",
      "9720/9720 [==============================] - 33s 3ms/step - loss: 0.0096 - val_loss: 0.0072\n",
      "Epoch 16/100\n",
      "9720/9720 [==============================] - 29s 3ms/step - loss: 0.0096 - val_loss: 0.0078\n",
      "Sampling Strategy: 0.15\n",
      "Dropout 5\n",
      "The best epoch is: 6\n",
      "The validation loss at the best epoch is: 0.006940094754099846\n",
      "2700/2700 [==============================] - 3s 1ms/step\n",
      "\n",
      "Dropout: 5\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92     75125\n",
      "           1       0.28      0.04      0.07     11269\n",
      "\n",
      "    accuracy                           0.86     86394\n",
      "   macro avg       0.58      0.51      0.50     86394\n",
      "weighted avg       0.80      0.86      0.81     86394\n",
      "\n",
      "Epoch 1/100\n",
      "10565/10565 [==============================] - 34s 3ms/step - loss: 0.0156 - val_loss: 0.0092\n",
      "Epoch 2/100\n",
      "10565/10565 [==============================] - 31s 3ms/step - loss: 0.0117 - val_loss: 0.0078\n",
      "Epoch 3/100\n",
      "10565/10565 [==============================] - 36s 3ms/step - loss: 0.0108 - val_loss: 0.0073\n",
      "Epoch 4/100\n",
      "10565/10565 [==============================] - 30s 3ms/step - loss: 0.0103 - val_loss: 0.0071\n",
      "Epoch 5/100\n",
      "10565/10565 [==============================] - 32s 3ms/step - loss: 0.0102 - val_loss: 0.0070\n",
      "Epoch 6/100\n",
      "10565/10565 [==============================] - 35s 3ms/step - loss: 0.0101 - val_loss: 0.0071\n",
      "Epoch 7/100\n",
      "10565/10565 [==============================] - 34s 3ms/step - loss: 0.0100 - val_loss: 0.0071\n",
      "Epoch 8/100\n",
      "10565/10565 [==============================] - 32s 3ms/step - loss: 0.0100 - val_loss: 0.0069\n",
      "Epoch 9/100\n",
      "10565/10565 [==============================] - 30s 3ms/step - loss: 0.0099 - val_loss: 0.0070\n",
      "Epoch 10/100\n",
      "10565/10565 [==============================] - 36s 3ms/step - loss: 0.0099 - val_loss: 0.0071\n",
      "Epoch 11/100\n",
      "10565/10565 [==============================] - 37s 3ms/step - loss: 0.0098 - val_loss: 0.0068\n",
      "Epoch 12/100\n",
      "10565/10565 [==============================] - 37s 4ms/step - loss: 0.0096 - val_loss: 0.0064\n",
      "Epoch 13/100\n",
      "10565/10565 [==============================] - 1455s 138ms/step - loss: 0.0094 - val_loss: 0.0061\n",
      "Epoch 14/100\n",
      "10565/10565 [==============================] - 42s 4ms/step - loss: 0.0093 - val_loss: 0.0062\n",
      "Epoch 15/100\n",
      "10565/10565 [==============================] - 35s 3ms/step - loss: 0.0093 - val_loss: 0.0062\n",
      "Epoch 16/100\n",
      "10565/10565 [==============================] - 34s 3ms/step - loss: 0.0092 - val_loss: 0.0066\n",
      "Epoch 17/100\n",
      "10565/10565 [==============================] - 49s 5ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 18/100\n",
      "10565/10565 [==============================] - 56s 5ms/step - loss: 0.0092 - val_loss: 0.0064\n",
      "Epoch 19/100\n",
      "10565/10565 [==============================] - 61s 6ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 20/100\n",
      "10565/10565 [==============================] - 61s 6ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 21/100\n",
      "10565/10565 [==============================] - 54s 5ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 22/100\n",
      "10565/10565 [==============================] - 61s 6ms/step - loss: 0.0092 - val_loss: 0.0062\n",
      "Epoch 23/100\n",
      "10565/10565 [==============================] - 65s 6ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 24/100\n",
      "10565/10565 [==============================] - 62s 6ms/step - loss: 0.0092 - val_loss: 0.0064\n",
      "Epoch 25/100\n",
      "10565/10565 [==============================] - 62s 6ms/step - loss: 0.0091 - val_loss: 0.0062\n",
      "Epoch 26/100\n",
      "10565/10565 [==============================] - 65s 6ms/step - loss: 0.0091 - val_loss: 0.0069\n",
      "Epoch 27/100\n",
      "10565/10565 [==============================] - 56s 5ms/step - loss: 0.0091 - val_loss: 0.0062\n",
      "Epoch 28/100\n",
      "10565/10565 [==============================] - 59s 6ms/step - loss: 0.0091 - val_loss: 0.0061\n",
      "Epoch 29/100\n",
      "10565/10565 [==============================] - 54s 5ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Sampling Strategy: 0.25\n",
      "Dropout 5\n",
      "The best epoch is: 19\n",
      "The validation loss at the best epoch is: 0.006033600773662329\n",
      "2935/2935 [==============================] - 6s 2ms/step\n",
      "\n",
      "Dropout: 5\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88     75125\n",
      "           1       0.36      0.04      0.07     18781\n",
      "\n",
      "    accuracy                           0.79     93906\n",
      "   macro avg       0.58      0.51      0.48     93906\n",
      "weighted avg       0.71      0.79      0.72     93906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the autoencoder model - training is mix of cancerous and non-cancerous: dropout of 5 works best\n",
    "# Oversample the minority group to make the data more balanced\n",
    "best = ()\n",
    "for ss in range(5, 50, 15):\n",
    "    smote = SMOTE(sampling_strategy=ss*0.01, random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(skin_cancer_df.iloc[:, 1:], skin_cancer_df.iloc[:, 0])\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_rest, y_train, y_rest = train_test_split(X_resampled, y_resampled, stratify=y_resampled, random_state=42)\n",
    "    X_validation, X_test, y_validation, y_test = train_test_split(X_rest, y_rest, stratify=y_rest, random_state=42)\n",
    "\n",
    "    # Scale the data between 0 and 1\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_validation = scaler.transform(X_validation)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    autoencoder = Sequential([\n",
    "            Dense(128, input_dim=X_train.shape[1], activation=None),\n",
    "            BatchNormalization(),  # Apply BatchNormalization\n",
    "            Activation('relu'),     # Then apply activation function\n",
    "            Dropout(0.5),           # Optional dropout for regularization\n",
    "\n",
    "            Dense(64, activation=None),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Dropout(0.5),\n",
    "\n",
    "            Dense(32, activation=None),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "\n",
    "            Dense(64, activation=None),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Dropout(0.5),\n",
    "\n",
    "            Dense(128, activation=None),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Dropout(0.5),\n",
    "        \n",
    "            Dense(X_train.shape[1], activation='sigmoid')  # Output layer should match input\n",
    "    ])\n",
    "\n",
    "\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the autoencoder\n",
    "    history = autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, validation_split=0.1,\n",
    "                                 callbacks=[early_stopping])\n",
    "\n",
    "    # Find the epoch with the lowest validation loss\n",
    "    best_epoch = np.argmin(history.history['val_loss']) + 1  # Add 1 since epochs are 1-indexed\n",
    "    best_val_loss = np.min(history.history['val_loss'])\n",
    "\n",
    "    print('Sampling Strategy:', ss*0.01)\n",
    "    print('Dropout', d)\n",
    "    print(f\"The best epoch is: {best_epoch}\")\n",
    "    print(f\"The validation loss at the best epoch is: {best_val_loss}\")\n",
    "\n",
    "    # Calculate reconstruction error for each sample\n",
    "    reconstructed = autoencoder.predict(X_validation)\n",
    "    reconstruction_error = np.mean(np.abs(reconstructed - X_validation), axis=1)  \n",
    "\n",
    "    # Threshold the reconstruction error to detect anomalies\n",
    "    threshold = np.percentile(reconstruction_error, 98)  # Set threshold (e.g., 99th percentile)\n",
    "    predictions_autoencoder = (reconstruction_error > threshold).astype(int)  # 1 = anomaly (cancer), 0 = normal\n",
    "    cf = classification_report(y_validation, predictions_autoencoder)\n",
    "    print(f'\\nDropout: {d}\\n')\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52adf1f3",
   "metadata": {},
   "source": [
    "# Method 4: Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e509c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19492\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\19492\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\19492\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\19492\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S=5, N=25\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     75125\n",
      "           1       0.13      1.00      0.23     11269\n",
      "\n",
      "    accuracy                           0.13     86394\n",
      "   macro avg       0.07      0.50      0.12     86394\n",
      "weighted avg       0.02      0.13      0.03     86394\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19492\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\19492\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\19492\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S=5, N=35\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     75125\n",
      "           1       0.13      1.00      0.23     11269\n",
      "\n",
      "    accuracy                           0.13     86394\n",
      "   macro avg       0.07      0.50      0.12     86394\n",
      "weighted avg       0.02      0.13      0.03     86394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "for ss in range(5, 15, 10):\n",
    "    smote = SMOTE(sampling_strategy=ss*0.01, random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(skin_cancer_df.iloc[:, 1:], skin_cancer_df.iloc[:, 0])\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_rest, y_train, y_rest = train_test_split(X_resampled, y_resampled, stratify=y_resampled, random_state=42)\n",
    "    X_validation, X_test, y_validation, y_test = train_test_split(X_rest, y_rest, stratify=y_rest, random_state=42)\n",
    "\n",
    "    # Scale the data between 0 and 1\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_validation = scaler.transform(X_validation)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # n= 25 ==> best\n",
    "    for n in range(25, 55, 10):\n",
    "        # Perform LOF on the training data\n",
    "        c = len([1 for target in y_train if target == 1]) / len(y_train)\n",
    "        lof = LocalOutlierFactor(n_neighbors=n, contamination=c, novelty=True)\n",
    "\n",
    "        # Fit the model on the training data\n",
    "        lof.fit(X_train)\n",
    "\n",
    "        # Predict the targets for the validation data\n",
    "        lof_validation_preds = lof.predict(X_validation)\n",
    "\n",
    "        # Convert LOF predictions to binary (1 for cancerous, 0 for non-cancerous)\n",
    "        y_pred_valid = [1 if p == -1 else 0 for p in lof_validation_preds]\n",
    "\n",
    "        # Evaluate the model's performance on the validation data\n",
    "        cr = classification_report(y_validation, y_pred_valid)\n",
    "        print(f'\\nS={ss}, N={n}\\n', cr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
